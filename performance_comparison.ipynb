{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "#from keras import backend as K\n",
    "#K.set_image_data_format('channels_last')\n",
    "from ImageDataAugmentor.image_data_augmentor import *\n",
    "import albumentations\n",
    "from datetime import datetime\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:                      Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz\r\n"
     ]
    }
   ],
   "source": [
    "!lscpu | grep \"Model name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6812 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "def image_preprocessing(x):\n",
    "    x = x/255. # rescale to [0,1]\n",
    "    return(x)\n",
    "    \n",
    "TEST_AUGMENTATIONS = albumentations.Compose([\n",
    "    albumentations.HorizontalFlip(p=0.5)\n",
    "])\n",
    "\n",
    "img_test_data_gen = ImageDataAugmentor(augment=TEST_AUGMENTATIONS, \n",
    "                                  augment_seed=123,\n",
    "                                  preprocess_input = image_preprocessing)\n",
    "img_test_gen = img_test_data_gen.flow_from_directory('./test_data/img', \n",
    "                                           class_mode=None, \n",
    "                                           shuffle=True, \n",
    "                                           seed=123, \n",
    "                                           color_mode='rgb', \n",
    "                                           target_size=(512, 512),\n",
    "                                           batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(model):\n",
    "    image_batch = next(img_test_gen)\n",
    "    for i in range(4):\n",
    "        start = datetime.now()\n",
    "        pred = model.predict_on_batch(np.expand_dims(image_batch[i,:,:,:], axis=0))\n",
    "        end = datetime.now()\n",
    "        print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, NamedTuple\n",
    "class Rectangle(NamedTuple):\n",
    "    \"\"\"Хранит координаты прямоугольника (xmin, ymin) - (xmax, ymax)\"\"\"\n",
    "\n",
    "    xmin: int\n",
    "    ymin: int\n",
    "    xmax: int\n",
    "    ymax: int\n",
    "\n",
    "    @property\n",
    "    def w(self) -> int:\n",
    "        \"\"\"Ширина\"\"\"\n",
    "        return self.xmax - self.xmin\n",
    "\n",
    "    @property\n",
    "    def h(self) -> int:\n",
    "        \"\"\"Высота\"\"\"\n",
    "        return self.ymax - self.ymin\n",
    "\n",
    "    @property\n",
    "    def square(self) -> float:\n",
    "        \"\"\"Площадь\"\"\"\n",
    "        return self.w * self.h\n",
    "\n",
    "\n",
    "def image_grid(image_w: int, image_h: int,\n",
    "               window_w: int, window_h: int,\n",
    "               overlap_w: int, overlap_h: int) -> List[Rectangle]:\n",
    "    \"\"\"Рассчитывает координаты прямоугольников для разбиения изображения на блоки\n",
    "    :param image_w: ширина изображения\n",
    "    :param image_h: высота изображения\n",
    "    :param window_w: ширина прямоугольника\n",
    "    :param window_h: высота прямоугольника\n",
    "    :param overlap_w: перекрытие прямоугольников по горизонтали\n",
    "    :param overlap_h: перекрытие прямоугольников по вертикали\n",
    "    \"\"\"\n",
    "    rectangles = []\n",
    "    # комбинируем вертикальный и горизонтальные разрезы, чтобы получить прямоугольники\n",
    "    for xmin in cut_points(image=image_w, window=window_w, overlap=overlap_w):\n",
    "        for ymin in cut_points(image=image_h, window=window_h, overlap=overlap_h):\n",
    "            rect = Rectangle(xmin=xmin, ymin=ymin, xmax=xmin + window_w, ymax=ymin + window_h)\n",
    "            rectangles.append(rect)\n",
    "    # избавляемся от повторов\n",
    "    return list(set(rectangles))\n",
    "\n",
    "def cut_points(image: int, window: int, overlap: int) -> List[int]:\n",
    "    \"\"\"Точки разрезов изображения (направляющие)\"\"\"\n",
    "    points = []\n",
    "    offset = window - overlap\n",
    "    for v in range(0, image - window, offset):\n",
    "        points.append(v)\n",
    "    # справа и снизу остается неполный прямоугольник\n",
    "    # добавим его, отсутпив справа ширину окна и сделаем еще один разрез\n",
    "    points.append(image - window)\n",
    "    return points\n",
    "\n",
    "def count_crops(height_ori=3000, width_ori=4000, window_w: int = 416, window_h: int = 416, overlap_w: int = 150, overlap_h: int = 150):\n",
    "    rects = image_grid(image_w=width_ori, image_h=height_ori,\n",
    "                        window_w=window_w, window_h=window_w,\n",
    "                        overlap_w=overlap_w, overlap_h=overlap_h)\n",
    "    return rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test performance on image 512*512\n",
    "\n",
    "## U-Net (resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:01.529350\n",
      "0:00:00.477358\n",
      "0:00:00.515232\n",
      "0:00:00.518919\n"
     ]
    }
   ],
   "source": [
    "model = sm.Unet(backbone_name='resnet18',\n",
    "    classes=1,\n",
    "    encoder_weights='imagenet',\n",
    "    input_shape=(512, 512, 3),\n",
    "    encoder_freeze=True)\n",
    "    \n",
    "model.compile('Adam', \n",
    "              loss=sm.losses.binary_focal_dice_loss,\n",
    "              metrics=[sm.metrics.iou_score, sm.metrics.f1_score])\n",
    "query(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net (resnet34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:02.173203\n",
      "0:00:00.558949\n",
      "0:00:00.599785\n",
      "0:00:00.569993\n"
     ]
    }
   ],
   "source": [
    "model = sm.Unet(backbone_name='resnet34',\n",
    "    classes=1,\n",
    "    encoder_weights='imagenet',\n",
    "    input_shape=(512, 512, 3),\n",
    "    encoder_freeze=True)\n",
    "\n",
    "model.compile('Adam', \n",
    "              loss=sm.losses.binary_focal_dice_loss,\n",
    "              metrics=[sm.metrics.iou_score, sm.metrics.f1_score])\n",
    "query(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net (resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:03.279154\n",
      "0:00:00.973155\n",
      "0:00:00.967939\n",
      "0:00:00.890561\n"
     ]
    }
   ],
   "source": [
    "model = sm.Unet(backbone_name='resnet50',\n",
    "    classes=1,\n",
    "    encoder_weights='imagenet',\n",
    "    input_shape=(512, 512, 3),\n",
    "    encoder_freeze=True)\n",
    "\n",
    "model.compile('Adam', \n",
    "              loss=sm.losses.binary_focal_dice_loss,\n",
    "              metrics=[sm.metrics.iou_score, sm.metrics.f1_score])\n",
    "query(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net (efn-B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:03.942730\n",
      "0:00:00.778575\n",
      "0:00:00.721337\n",
      "0:00:00.747951\n"
     ]
    }
   ],
   "source": [
    "model = sm.Unet(backbone_name='efficientnetb0',\n",
    "    classes=1,\n",
    "    encoder_weights='imagenet',\n",
    "    input_shape=(512, 512, 3),\n",
    "    encoder_freeze=True)\n",
    "\n",
    "model.compile('Adam', \n",
    "              loss=sm.losses.binary_focal_dice_loss,\n",
    "              metrics=[sm.metrics.iou_score, sm.metrics.f1_score])\n",
    "query(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net (efn-B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:05.713695\n",
      "0:00:00.978065\n",
      "0:00:00.956792\n",
      "0:00:00.970785\n"
     ]
    }
   ],
   "source": [
    "model = sm.Unet(backbone_name='efficientnetb2',\n",
    "    classes=1,\n",
    "    encoder_weights='imagenet',\n",
    "    input_shape=(512, 512, 3),\n",
    "    encoder_freeze=True)\n",
    "\n",
    "model.compile('Adam', \n",
    "              loss=sm.losses.binary_focal_dice_loss,\n",
    "              metrics=[sm.metrics.iou_score, sm.metrics.f1_score])\n",
    "query(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net (mobilenet-v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gosha20777/anaconda3/envs/tf-1-14/lib/python3.7/site-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:03.919622\n",
      "0:00:00.656635\n",
      "0:00:00.602401\n",
      "0:00:00.575693\n"
     ]
    }
   ],
   "source": [
    "model = sm.Unet(backbone_name='mobilenet',\n",
    "    classes=1,\n",
    "    encoder_weights='imagenet',\n",
    "    input_shape=(512, 512, 3),\n",
    "    encoder_freeze=True)\n",
    "\n",
    "model.compile('Adam', \n",
    "              loss=sm.losses.binary_focal_dice_loss,\n",
    "              metrics=[sm.metrics.iou_score, sm.metrics.f1_score])\n",
    "query(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net (Custom-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras.layers import Input, Dense, Concatenate, Convolution2D, MaxPooling2D, UpSampling2D, BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback, ModelCheckpoint\n",
    "from keras.utils import Sequence\n",
    "from keras.regularizers import l2\n",
    "\n",
    "def model1(img_rows, img_cols, optimizer, reg=0.1):\n",
    "    '''https://github.com/yihui-he/u-net'''\n",
    "    inputs = Input(shape=(img_rows, img_cols, 3))\n",
    "    bn1 = BatchNormalization()(inputs)\n",
    "    conv1 = Convolution2D(32, (3, 3), activation='relu', padding='same')(bn1)\n",
    "    conv1 = Convolution2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Convolution2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Convolution2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Convolution2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Convolution2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Convolution2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Convolution2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    conv5 = Convolution2D(512, (3, 3), activation='elu', padding='same')(pool4)\n",
    "    conv5 = Convolution2D(512, (3, 3), activation='elu', padding='same')(conv5)\n",
    "    up6 = Concatenate()([Convolution2D(256, (2, 2), activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv5)), conv4])\n",
    "    conv6 = Convolution2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Convolution2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    up7 = Concatenate()([Convolution2D(128, (2, 2),activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6)), conv3])\n",
    "    conv7 = Convolution2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Convolution2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    up8 = Concatenate()([Convolution2D(64, (2, 2),activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv7)), conv2])\n",
    "    conv8 = Convolution2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Convolution2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    up9 = Concatenate()([Convolution2D(32, (2, 2),activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv8)), conv1])\n",
    "    conv9 = Convolution2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Convolution2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    bn = BatchNormalization()(conv9)    \n",
    "    conv10 = Convolution2D(1, (1, 1), activation='sigmoid')(bn)\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "    for layer in range(len(model.layers)):\n",
    "        model.layers[layer].kernel_regularizer=l2(reg)\n",
    "        model.layers[layer].bias_regularizer=l2(reg)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "\n",
    "    print('U-Net compiled,  batch_norm1=True, batch_norm10=True, 4 skips.')\n",
    "    print('Input shape:', model.input_shape)\n",
    "    print('Output shape:', model.output_shape)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U-Net compiled,  batch_norm1=True, batch_norm10=True, 4 skips.\n",
      "Input shape: (None, 512, 512, 3)\n",
      "Output shape: (None, 512, 512, 1)\n",
      "0:00:03.602837\n",
      "0:00:00.623623\n",
      "0:00:00.623829\n",
      "0:00:00.640058\n"
     ]
    }
   ],
   "source": [
    "model = model1(512, 512, optimizer=Adam(learning_rate=1e-3))\n",
    "query(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linknet (resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gosha20777/anaconda3/envs/tf-1-14/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "0:00:01.227597\n",
      "0:00:00.246398\n",
      "0:00:00.254326\n",
      "0:00:00.257347\n"
     ]
    }
   ],
   "source": [
    "model = sm.Linknet(backbone_name='resnet18',\n",
    "    classes=1,\n",
    "    encoder_weights='imagenet',\n",
    "    input_shape=(None, None, 3),\n",
    "    encoder_freeze=True)\n",
    "\n",
    "model.compile('Adam', \n",
    "              loss=sm.losses.binary_focal_dice_loss,\n",
    "              metrics=[sm.metrics.iou_score, sm.metrics.f1_score])\n",
    "query(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5tw66lel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5tw66lel/assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "tflite = converter.convert()\n",
    "\n",
    "with open(\"Linknet.tflite\",\"wb\") as h:\n",
    "    h.write(tflite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### int8 quanitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqst0_2xg/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqst0_2xg/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibration image test_data/img/1/146___p04982.jpg\n",
      "calibration image test_data/img/1/256___p04096.jpg\n",
      "calibration image test_data/img/1/77___n00110.jpg\n",
      "calibration image test_data/img/1/50___p00978.jpg\n",
      "calibration image test_data/img/1/32___n00341.jpg\n",
      "calibration image test_data/img/1/18___n02883.jpg\n",
      "calibration image test_data/img/1/329___p03688.jpg\n",
      "calibration image test_data/img/1/46___p05597.jpg\n",
      "calibration image test_data/img/1/296___p05680.jpg\n",
      "calibration image test_data/img/1/385___p04509.jpg\n"
     ]
    }
   ],
   "source": [
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "def representative_data_gen():\n",
    "    fimage = glob.glob('test_data/img/1/*.jpg')\n",
    "    for input_value in range(10):\n",
    "        if os.path.exists(fimage[input_value]):\n",
    "            original_image=cv2.imread(fimage[input_value])\n",
    "            image_data = cv2.resize(original_image, (512,512))\n",
    "            image_data = preprocess_image(image_data)\n",
    "            img_in = image_data[np.newaxis, ...].astype(np.float32)\n",
    "            print(\"calibration image {}\".format(fimage[input_value]))\n",
    "            yield [img_in]\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "#converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "#converter.target_spec.supported_ops = [\n",
    "#    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "#    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "#]\n",
    "#converter.allow_custom_ops = True\n",
    "#converter.representative_dataset = representative_data_gen\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "\n",
    "tflite = converter.convert()\n",
    "\n",
    "with open(\"model_int8.tflite\",\"wb\") as h:\n",
    "    h.write(tflite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'data', 'index': 0, 'shape': array([  1, 512, 512,   3], dtype=int32), 'shape_signature': array([ -1, 512, 512,   3], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.006827473640442, -23), 'quantization_parameters': {'scales': array([1.0068275], dtype=float32), 'zero_points': array([-23], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'Identity', 'index': 187, 'shape': array([1, 1, 1, 1], dtype=int32), 'shape_signature': array([-1, -1, -1,  1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='model_int8.tflite')\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = cv2.imread('test_data/img/1/0___n04759.jpg')\n",
    "image_data = cv2.resize(original_image, (512,512))\n",
    "image_data = preprocess_image(image_data)\n",
    "#image_data = image_data / 255.\n",
    "image_data = np.expand_dims(image_data, axis=0)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:24.419191\n"
     ]
    }
   ],
   "source": [
    "def set_input_tensor(interpreter, input):\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    tensor_index = input_details['index']\n",
    "    input_tensor = interpreter.tensor(tensor_index)()[0]\n",
    "    # Inputs for the TFLite model must be uint8, so we quantize our input data.\n",
    "    # NOTE: This step is necessary only because we're receiving input data from\n",
    "    # ImageDataGenerator, which rescaled all image data to float [0,1]. When using\n",
    "    # bitmap inputs, they're already uint8 [0,255] so this can be replaced with:\n",
    "    #   input_tensor[:, :] = input\n",
    "    scale, zero_point = input_details['quantization']\n",
    "    input_tensor[:, :] = np.uint8(input / scale + zero_point)\n",
    "\n",
    "start = datetime.now()\n",
    "set_input_tensor(interpreter, image_data)\n",
    "#interpreter.set_tensor(input_details[0]['index'], image_data)\n",
    "interpreter.invoke()\n",
    "pred = [interpreter.get_tensor(output_details[i]['index']) for i in range(len(output_details))]\n",
    "end = datetime.now()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenVino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('linknet_resnet_18.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 519 variables.\n",
      "INFO:tensorflow:Converted 519 variables to const ops.\n",
      "weights saved!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
    "            session, input_graph_def, output_names, freeze_var_names)\n",
    "        return frozen_graph\n",
    "\n",
    "K.set_learning_phase(0)    \n",
    "    \n",
    "weights_name = 'linknet_resnet_18.h5'\n",
    "\n",
    "model = sm.Linknet(backbone_name='resnet18',\n",
    "    classes=1,\n",
    "    encoder_weights='imagenet',\n",
    "    input_shape=(512, 512, 3),\n",
    "    encoder_freeze=True)\n",
    "\n",
    "model.load_weights(weights_name)\n",
    "frozen_graph = freeze_session(K.get_session(), output_names=[out.op.name for out in model.outputs])\n",
    "tf.train.write_graph(frozen_graph, '.', 'linknet_resnet_18.pb', as_text=False)\n",
    "print(f'weights saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setupvars.sh] OpenVINO environment initialized\n",
      "initialize OpenVino...\n",
      "[E:] [BSL] found 0 ioexpander device\n",
      "\u001b[35mE: [xLinkUsb] [    850384] [python3] usb_find_device_with_bcd:265\tLibrary has not been initialized when loaded\u001b[0m\n",
      "available devices:  ['CPU', 'GNA']\n",
      "loading model...\n",
      "inference_openvino.py:86: DeprecationWarning: Reading network using constructor is deprecated. Please, use IECore.read_network() method instead\n",
      "  net = IENetwork(model=model_xml, weights=model_bin)\n",
      "inference_openvino.py:93: DeprecationWarning: 'inputs' property of IENetwork class is deprecated. To access DataPtrs user need to use 'input_data' property of InputInfoPtr objects which can be accessed by 'input_info' property.\n",
      "  _, _, h, w = net.inputs[input_blob].shape\n",
      "model input shape: [1, 3, 416, 416]\n",
      "make 4 predictions:\n",
      "\t0.046399593353271484 s\n",
      "\t0.04608607292175293 s\n",
      "\t0.04748845100402832 s\n",
      "\t0.0509800910949707 s\n"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm -v `pwd`:/lacmus --workdir /lacmus/ openvino/ubuntu18_dev:latest \\\n",
    "    bash -c \"source /opt/intel/openvino_2020.4.287/bin/setupvars.sh && python3 inference_openvino.py --bin linknet_resnet_18_416.bin --xml linknet_resnet_18_416.xml --img test_data/img/1/0___n04761.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setupvars.sh] OpenVINO environment initialized\n",
      "initialize OpenVino...\n",
      "[E:] [BSL] found 0 ioexpander device\n",
      "\u001b[35mE: [xLinkUsb] [    893910] [python3] usb_find_device_with_bcd:265\tLibrary has not been initialized when loaded\u001b[0m\n",
      "available devices:  ['CPU', 'GNA']\n",
      "loading model...\n",
      "inference_openvino.py:86: DeprecationWarning: Reading network using constructor is deprecated. Please, use IECore.read_network() method instead\n",
      "  net = IENetwork(model=model_xml, weights=model_bin)\n",
      "inference_openvino.py:93: DeprecationWarning: 'inputs' property of IENetwork class is deprecated. To access DataPtrs user need to use 'input_data' property of InputInfoPtr objects which can be accessed by 'input_info' property.\n",
      "  _, _, h, w = net.inputs[input_blob].shape\n",
      "model input shape: [1, 3, 512, 512]\n",
      "make 4 predictions:\n",
      "\t0.07027435302734375 s\n",
      "\t0.07549619674682617 s\n",
      "\t0.06219816207885742 s\n",
      "\t0.07791805267333984 s\n"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm -v `pwd`:/lacmus --workdir /lacmus/ openvino/ubuntu18_dev:latest \\\n",
    "    bash -c \"source /opt/intel/openvino_2020.4.287/bin/setupvars.sh && python3 inference_openvino.py --bin linknet_resnet_18_512.bin --xml linknet_resnet_18_512.xml --img test_data/img/1/0___n04761.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setupvars.sh] OpenVINO environment initialized\n",
      "initialize OpenVino...\n",
      "[E:] [BSL] found 0 ioexpander device\n",
      "\u001b[35mE: [xLinkUsb] [    504376] [python3] usb_find_device_with_bcd:265\tLibrary has not been initialized when loaded\u001b[0m\n",
      "available devices:  ['CPU', 'GNA']\n",
      "loading model...\n",
      "inference_openvino.py:86: DeprecationWarning: Reading network using constructor is deprecated. Please, use IECore.read_network() method instead\n",
      "  net = IENetwork(model=model_xml, weights=model_bin)\n",
      "inference_openvino.py:93: DeprecationWarning: 'inputs' property of IENetwork class is deprecated. To access DataPtrs user need to use 'input_data' property of InputInfoPtr objects which can be accessed by 'input_info' property.\n",
      "  _, _, h, w = net.inputs[input_blob].shape\n",
      "model input shape: [1, 3, 608, 608]\n",
      "make 4 predictions:\n",
      "\t0.10514974594116211 s\n",
      "\t0.10730624198913574 s\n",
      "\t0.10131478309631348 s\n",
      "\t0.10210633277893066 s\n"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm -v `pwd`:/lacmus --workdir /lacmus/ openvino/ubuntu18_dev:latest \\\n",
    "    bash -c \"source /opt/intel/openvino_2020.4.287/bin/setupvars.sh && python3 inference_openvino.py --bin linknet_resnet_18_608.bin --xml linknet_resnet_18_608.xml --img test_data/img/1/0___n04761.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setupvars.sh] OpenVINO environment initialized\n",
      "initialize OpenVino...\n",
      "[E:] [BSL] found 0 ioexpander device\n",
      "\u001b[35mE: [xLinkUsb] [    240756] [python3] usb_find_device_with_bcd:265\tLibrary has not been initialized when loaded\u001b[0m\n",
      "available devices:  ['CPU', 'GNA']\n",
      "loading model...\n",
      "inference_openvino.py:86: DeprecationWarning: Reading network using constructor is deprecated. Please, use IECore.read_network() method instead\n",
      "  net = IENetwork(model=model_xml, weights=model_bin)\n",
      "inference_openvino.py:93: DeprecationWarning: 'inputs' property of IENetwork class is deprecated. To access DataPtrs user need to use 'input_data' property of InputInfoPtr objects which can be accessed by 'input_info' property.\n",
      "  _, _, h, w = net.inputs[input_blob].shape\n",
      "model input shape: [1, 3, 704, 704]\n",
      "make 4 predictions:\n",
      "\t0.13303542137145996 s\n",
      "\t0.12978386878967285 s\n",
      "\t0.12861371040344238 s\n",
      "\t0.12896370887756348 s\n"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm -v `pwd`:/lacmus --workdir /lacmus/ openvino/ubuntu18_dev:latest \\\n",
    "    bash -c \"source /opt/intel/openvino_2020.4.287/bin/setupvars.sh && python3 inference_openvino.py --bin linknet_resnet_18_704.bin --xml linknet_resnet_18_704.xml --img test_data/img/1/0___n04761.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setupvars.sh] OpenVINO environment initialized\n",
      "initialize OpenVino...\n",
      "[E:] [BSL] found 0 ioexpander device\n",
      "\u001b[35mE: [xLinkUsb] [    925243] [python3] usb_find_device_with_bcd:265\tLibrary has not been initialized when loaded\u001b[0m\n",
      "available devices:  ['CPU', 'GNA']\n",
      "loading model...\n",
      "inference_openvino.py:86: DeprecationWarning: Reading network using constructor is deprecated. Please, use IECore.read_network() method instead\n",
      "  net = IENetwork(model=model_xml, weights=model_bin)\n",
      "inference_openvino.py:93: DeprecationWarning: 'inputs' property of IENetwork class is deprecated. To access DataPtrs user need to use 'input_data' property of InputInfoPtr objects which can be accessed by 'input_info' property.\n",
      "  _, _, h, w = net.inputs[input_blob].shape\n",
      "model input shape: [1, 3, 800, 800]\n",
      "make 4 predictions:\n",
      "\t0.16902804374694824 s\n",
      "\t0.16206574440002441 s\n",
      "\t0.16184186935424805 s\n",
      "\t0.16449570655822754 s\n"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm -v `pwd`:/lacmus --workdir /lacmus/ openvino/ubuntu18_dev:latest \\\n",
    "    bash -c \"source /opt/intel/openvino_2020.4.287/bin/setupvars.sh && python3 inference_openvino.py --bin linknet_resnet_18_800.bin --xml linknet_resnet_18_800.xml --img test_data/img/1/0___n04761.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setupvars.sh] OpenVINO environment initialized\n",
      "initialize OpenVino...\n",
      "[E:] [BSL] found 0 ioexpander device\n",
      "\u001b[35mE: [xLinkUsb] [    961720] [python3] usb_find_device_with_bcd:265\tLibrary has not been initialized when loaded\u001b[0m\n",
      "available devices:  ['CPU', 'GNA']\n",
      "loading model...\n",
      "inference_openvino.py:86: DeprecationWarning: Reading network using constructor is deprecated. Please, use IECore.read_network() method instead\n",
      "  net = IENetwork(model=model_xml, weights=model_bin)\n",
      "inference_openvino.py:93: DeprecationWarning: 'inputs' property of IENetwork class is deprecated. To access DataPtrs user need to use 'input_data' property of InputInfoPtr objects which can be accessed by 'input_info' property.\n",
      "  _, _, h, w = net.inputs[input_blob].shape\n",
      "model input shape: [1, 3, 1024, 1024]\n",
      "make 4 predictions:\n",
      "\t0.2740461826324463 s\n",
      "\t0.2689168453216553 s\n",
      "\t0.2706468105316162 s\n",
      "\t0.2675347328186035 s\n"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm -v `pwd`:/lacmus --workdir /lacmus/ openvino/ubuntu18_dev:latest \\\n",
    "    bash -c \"source /opt/intel/openvino_2020.4.287/bin/setupvars.sh && python3 inference_openvino.py --bin linknet_resnet_18_1024.bin --xml linknet_resnet_18_1024.xml --img test_data/img/1/0___n04761.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f516437cb50>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [416, 512, 608, 704, 800, 1024]\n",
    "y = [0.047, 0.071, 0.103, 0.129, 0.164, 0.265]\n",
    "plt.plot(x, y, marker=\"o\", c=\"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_416_full = len(count_crops(height_ori=3000, width_ori=4000,\n",
    "                             window_w=416, window_h=416))\n",
    "count_416_half = len(count_crops(height_ori=1500, width_ori=2000,\n",
    "                             window_w=416, window_h=416))\n",
    "count_512_full = len(count_crops(height_ori=3000, width_ori=4000,\n",
    "                             window_w=512, window_h=512))\n",
    "count_512_half = len(count_crops(height_ori=1500, width_ori=2000,\n",
    "                             window_w=512, window_h=512))\n",
    "count_608_full = len(count_crops(height_ori=3000, width_ori=4000,\n",
    "                             window_w=608, window_h=608))\n",
    "count_608_half = len(count_crops(height_ori=1500, width_ori=2000,\n",
    "                             window_w=608, window_h=608))\n",
    "count_704_full = len(count_crops(height_ori=3000, width_ori=4000,\n",
    "                             window_w=704, window_h=704))\n",
    "count_704_half = len(count_crops(height_ori=1500, width_ori=2000,\n",
    "                             window_w=704, window_h=704))\n",
    "count_800_full = len(count_crops(height_ori=3000, width_ori=4000,\n",
    "                             window_w=800, window_h=800))\n",
    "count_800_half = len(count_crops(height_ori=1500, width_ori=2000,\n",
    "                             window_w=800, window_h=800))\n",
    "count_1024_full = len(count_crops(height_ori=3000, width_ori=4000,\n",
    "                             window_w=1024, window_h=1024))\n",
    "count_1024_half = len(count_crops(height_ori=1500, width_ori=2000,\n",
    "                             window_w=1024, window_h=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5164336950>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [416, 512, 608, 704, 800, 1024]\n",
    "y = [0.047*count_416_full,\n",
    "     0.071*count_512_full,\n",
    "     0.103*count_608_full,\n",
    "     0.129*count_704_full,\n",
    "     0.164*count_800_full,\n",
    "     0.265*count_1024_full]\n",
    "\n",
    "plt.plot(x, y, marker=\"o\", c=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f51642a1950>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [416, 512, 608, 704, 800, 1024]\n",
    "y = [0.047*count_416_half,\n",
    "     0.071*count_512_half,\n",
    "     0.103*count_608_half,\n",
    "     0.129*count_704_half,\n",
    "     0.164*count_800_half,\n",
    "     0.265*count_1024_half]\n",
    "\n",
    "plt.plot(x, y, marker=\"o\", c=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.328s vs 1s\n"
     ]
    }
   ],
   "source": [
    "time = len(count_crops(height_ori=1333, width_ori=800,\n",
    "                             window_w=800, window_h=800))*0.164\n",
    "print(f'{time}s vs 1s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras-Retinanet (resnet-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable_5:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_6:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_7:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_8:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_9:0' shape=(9, 4) dtype=float32> anchors\n",
      "indices.shape[-1]: 1 <= params.rank: 2 and shape (?, 4)\n",
      "indices.shape[-1]: 1 <= params.rank: 1 and shape (?,)\n",
      "indices.shape[-1]: 2 <= params.rank: 2 and shape (?, 1)\n",
      "0:00:03.942450\n",
      "0:00:00.347900\n",
      "0:00:00.343302\n",
      "0:00:00.356467\n"
     ]
    }
   ],
   "source": [
    "from keras_retinanet import models\n",
    "\n",
    "def create_model(backbone_name, num_classes=1):\n",
    "    backbone_factory = models.backbone(backbone_name)\n",
    "    model = backbone_factory.retinanet(num_classes)\n",
    "    return models.convert_model(model)\n",
    "\n",
    "backbone = 'resnet50'\n",
    "model = create_model(backbone)\n",
    "query(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable_10:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_11:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_12:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_13:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_14:0' shape=(9, 4) dtype=float32> anchors\n",
      "indices.shape[-1]: 1 <= params.rank: 2 and shape (?, 4)\n",
      "indices.shape[-1]: 1 <= params.rank: 1 and shape (?,)\n",
      "indices.shape[-1]: 2 <= params.rank: 2 and shape (?, 1)\n",
      "0:00:07.703907\n",
      "0:00:00.541582\n",
      "0:00:00.542402\n",
      "0:00:00.551486\n"
     ]
    }
   ],
   "source": [
    "backbone = 'EfficientNetB0'\n",
    "model = create_model(backbone)\n",
    "query(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras-Retinanet (mobilenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable_10:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_11:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_12:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_13:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_14:0' shape=(9, 4) dtype=float32> anchors\n",
      "indices.shape[-1]: 1 <= params.rank: 2 and shape (?, 4)\n",
      "indices.shape[-1]: 1 <= params.rank: 1 and shape (?,)\n",
      "indices.shape[-1]: 2 <= params.rank: 2 and shape (?, 1)\n",
      "0:00:03.493817\n",
      "0:00:00.174082\n",
      "0:00:00.245533\n",
      "0:00:00.190339\n"
     ]
    }
   ],
   "source": [
    "backbone = 'mobilenet224_0.1'\n",
    "model = create_model(backbone)\n",
    "query(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO 4-tf (416*416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.658849\n",
      "0:00:00.255762\n",
      "0:00:00.254708\n",
      "0:00:00.265157\n"
     ]
    }
   ],
   "source": [
    "!cd ../tensorflow-yolov4-tflite && \\\n",
    "   python detect.py --weights ./checkpoints/yolov4-416 \\\n",
    "   --size 416 --model yolov4 \\\n",
    "   --image ../lacmus-research/test_data/img/1/0___n04759.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO 4-tf-tiny (416*416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.142459\n",
      "0:00:00.025333\n",
      "0:00:00.028778\n",
      "0:00:00.026272\n"
     ]
    }
   ],
   "source": [
    "!cd ../tensorflow-yolov4-tflite && \\\n",
    "   python detect.py --weights ./checkpoints/yolov4-tiny-416 \\\n",
    "   --size 416 --model yolov4 \\\n",
    "   --image ../lacmus-research/test_data/img/1/0___n04759.jpg --tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
