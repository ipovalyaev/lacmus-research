{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18eb7778-ce54-47e6-8374-fcfac896709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "785c3d18-6b28-4c78-a9ea-bafaa98ba888",
   "metadata": {},
   "outputs": [],
   "source": [
    "LADD_PATH= '../../ladd-and-weights/dataset/full_train_ds'\n",
    "HERIDAL_PATH = '../../ladd-and-weights/dataset/3rd_party/heridal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "553f57f5-f646-4198-bfa2-95aa7d0f201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get yolo5 code\n",
    "# !git clone git@github.com:ultralytics/yolov5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4bbd986-d144-4d01-971b-0eda81951a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get network settings \n",
    "# !cp -r ../networks/yolo5_settings ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a22b77c-1884-4ab6-9eb4-44402a4670fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "!rm -rf predict/exp\n",
    "!python ./yolov5/detect.py --augment --weights ../../ladd-and-weights/weights/yolo5/yolo5_fullDS_native.pt --source ../../ladd-and-weights/dataset/full_train_ds/JPEGImages --imgsz 1984 --conf-thres 0.05 --iou-thres 0.01 --project predict --nosave --save-txt --save-conf\n",
    "# !python ./yolov5/detect.py --augment --weights ../networks/yolov5/runs/train/exp3/weights/best.pt --source ../../ladd-and-weights/dataset/full_train_ds/JPEGImages --imgsz 1984 --conf-thres 0.05 --iou-thres 0.01 --project predict --nosave --save-txt --save-conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7758e4-8527-4a19-b6b6-bbd724e601f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf predict/exp2\n",
    "!python ./yolov5/detect.py --augment --weights ../../ladd-and-weights/weights/yolo5/yolo5_fullDS_native.pt --source ../../ladd-and-weights/dataset/3rd_party/heridal/JPEGImages --imgsz 1984 --conf-thres 0.05 --iou-thres 0.01 --project predict --nosave --save-txt --save-conf\n",
    "# !python ./yolov5/detect.py --augment --weights ../networks/yolov5/runs/train/exp3/weights/best.pt --source ../../ladd-and-weights/dataset/3rd_party/heridal/JPEGImages --imgsz 1984 --conf-thres 0.05 --iou-thres 0.01 --project predict --nosave --save-txt --save-conf\n",
    "!mv predict/exp2/labels/* predict/exp/labels/\n",
    "!rm -rf predict/exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d687dd41-e817-43da-a242-b5eb85bb0f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ladd_train_img = []\n",
    "ladd_test_img = []\n",
    "with open(os.path.join(LADD_PATH,'ImageSets/Main/train.txt'),'r') as file:\n",
    "    ladd_train_img.extend([s.strip() for s in file.readlines()])\n",
    "with open(os.path.join(LADD_PATH,'ImageSets/Main/val.txt'), 'r') as file:\n",
    "    ladd_test_img.extend([s.strip() for s in file.readlines()])\n",
    "with open(os.path.join(LADD_PATH,'ImageSets/Main/test.txt'),'r') as file:\n",
    "    ladd_test_img.extend([s.strip() for s in file.readlines()])\n",
    "\n",
    "#deduplicate (on some chunks test == val?)\n",
    "ladd_test_img = list(set(ladd_test_img))\n",
    "          \n",
    "          \n",
    "heridal_train_img = []\n",
    "heridal_test_img = []\n",
    "with open(os.path.join(HERIDAL_PATH,'ImageSets/Main/train.txt'), 'r') as file:\n",
    "    heridal_train_img.extend([s.strip() for s in file.readlines()])\n",
    "with open(os.path.join(HERIDAL_PATH,'ImageSets/Main/test.txt'), 'r') as file:\n",
    "    heridal_test_img.extend([s.strip() for s in file.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6236b8d3-9bff-4f58-9221-aa9da2405220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_voc_xml(node: ET.Element):\n",
    "    voc_dict = {}\n",
    "    children = list(node)\n",
    "    if children:\n",
    "        def_dic = defaultdict(list)\n",
    "        for dc in map(parse_voc_xml, children):\n",
    "            for ind, v in dc.items():\n",
    "                def_dic[ind].append(v)\n",
    "        if node.tag == 'annotation':\n",
    "            def_dic['object'] = [def_dic['object']]\n",
    "        voc_dict = {\n",
    "            node.tag:\n",
    "                {ind: v[0] if len(v) == 1 else v\n",
    "                 for ind, v in def_dic.items()}\n",
    "        }\n",
    "    if node.text:\n",
    "        text = node.text.strip()\n",
    "        if not children:\n",
    "            voc_dict[node.tag] = text\n",
    "    return voc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be19f266-d6ee-4e7f-aa30-899db1e444e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_yolo_to_pixels(size,yolo_string):\n",
    "    s=[float(s) for s in  yolo_string.strip().split() ]\n",
    "    center_x=int(s[1]*size[0])\n",
    "    center_y=int(s[2]*size[1])\n",
    "    w=int(s[3]*size[0])\n",
    "    h=int(s[4]*size[1])\n",
    "    x1=int(center_x-w/2)\n",
    "    x2=int(center_x+w/2)\n",
    "    y1=int(center_y-h/2)\n",
    "    y2=int(center_y+h/2)\n",
    "    return (x1,y1,x2,y2,float(s[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "779c0f86-7cbf-4887-b54e-8df8f54f360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_and_preds(img_set, ds_path):\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    missed_files = 0\n",
    "    for im in img_set:\n",
    "        # Get true lables\n",
    "        file_name = os.path.join(ds_path,'Annotations',im+'.xml')\n",
    "        if not os.path.isfile(file_name):\n",
    "            missed_files+=1\n",
    "            # Some annotations in heridal missing???\n",
    "            continue\n",
    "\n",
    "        description = parse_voc_xml(ET.parse(file_name).getroot())\n",
    "        boxes = []\n",
    "        if 'annotation' in description:\n",
    "            for l in description['annotation']['object']:\n",
    "                bb = l['bndbox']\n",
    "                boxes.append((int(bb['xmin']), int(bb['ymin']), int(bb['xmax']), int(bb['ymax'])))\n",
    "            size = (int(description['annotation']['size']['width']),int(description['annotation']['size']['height']))\n",
    "        else: \n",
    "            # heridal somewhere contains no size in annotations\n",
    "            size = (4000,3000)\n",
    "        targets.append(boxes)\n",
    "        # Get predictions\n",
    "        file_name = os.path.join('./predict/exp/labels',im +'.txt')\n",
    "        this_predictions = []\n",
    "        if os.path.exists(file_name):\n",
    "            with open (file_name) as predictions_file:\n",
    "                this_predictions = [str.strip(s) for s in predictions_file.readlines()]\n",
    "                this_predictions = [convert_yolo_to_pixels(size,p) for p in this_predictions]\n",
    "        predictions.append(this_predictions)\n",
    "    if missed_files>0:\n",
    "        print('warning. ',missed_files, ' xmls are missing')\n",
    "    return targets,predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb49c557-1bc1-49af-b357-bc449d46a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_res(\n",
    "    targets,\n",
    "    detections, \n",
    "    iou_threshold=0.5,\n",
    "    score_threshold=0.05,\n",
    "    max_detections=100\n",
    "):\n",
    "    \"\"\" Evaluate a given dataset using a given model.\n",
    "    # Arguments\n",
    "        targets List [List [tuple(4)]]\n",
    "        prediction List [List [ tuple (5) ]] (with score)\n",
    "        targets and predictions top level list should have same len\n",
    "        iou_threshold   : The threshold used to consider when a detection is positive or negative.\n",
    "        score_threshold : The score confidence threshold to use for detections.\n",
    "        max_detections  : The maximum number of detections to use per image.\n",
    "    \"\"\"\n",
    "    if (len(targets) != len(detections)):\n",
    "        print (\"len(targets) %i != len(predictions) %i\"%(len(targets),len(detections)))\n",
    "        return 0\n",
    "\n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives  = np.zeros((0,))\n",
    "    scores          = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "\n",
    "    for i in range(len(targets)):\n",
    "        num_annotations     += len(targets[i])\n",
    "        detected_annotations = []\n",
    "\n",
    "        for d in range(len(detections[i])):\n",
    "            if detections[i][d][4] > score_threshold:\n",
    "                scores = np.append(scores, np.array(detections[i][d][4]))\n",
    "                if len(targets[i]) == 0: # no objects was there\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives  = np.append(true_positives, 0)\n",
    "                    continue\n",
    "                    \n",
    "                overlaps            = compute_overlap (np.array(detections[i][d])[np.newaxis,:4],np.array(targets[i]))\n",
    "                assigned_annotation = np.argmax(overlaps, axis=1)[0]\n",
    "                max_overlap         = overlaps[0, assigned_annotation]\n",
    "                \n",
    "\n",
    "                if max_overlap >= iou_threshold and assigned_annotation not in detected_annotations:\n",
    "                    false_positives = np.append(false_positives, 0)\n",
    "                    true_positives  = np.append(true_positives, 1)\n",
    "                    detected_annotations.append(assigned_annotation)\n",
    "                else:\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives  = np.append(true_positives, 0)\n",
    "\n",
    "    # F1@IoU\n",
    "    plain_recall = np.sum(true_positives)/num_annotations\n",
    "    plain_precision = np.sum(true_positives) / np.maximum(np.sum(true_positives) + np.sum(false_positives), np.finfo(np.float64).eps)\n",
    "    F1 = 2*plain_precision*plain_recall/(plain_precision+plain_recall)\n",
    "\n",
    "\n",
    "#     # sort by score\n",
    "    indices         = np.argsort(-scores)\n",
    "    false_positives = false_positives[indices]\n",
    "    true_positives  = true_positives[indices]\n",
    "\n",
    "#     # compute false positives and true positives\n",
    "    false_positives = np.cumsum(false_positives)\n",
    "    true_positives  = np.cumsum(true_positives)\n",
    "#     # compute recall and precision\n",
    "    recall    = true_positives / num_annotations\n",
    "    precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "    # compute average precision\n",
    "    average_precision  = compute_ap(recall, precision)\n",
    "\n",
    "\n",
    "    return (average_precision, plain_precision, plain_recall, F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7924e24a-3af8-4ac3-8c9a-5c9139aedb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAp@0.5, Precision, Recall, F1\n",
      "  train LADD\n",
      "(0.9223420704681259, 0.7777777777777778, 0.9282200357781754, 0.8463655826281986)\n",
      "  test LADD\n",
      "(0.9092969535286201, 0.615, 0.9290030211480362, 0.740072202166065)\n",
      "  train HERIAL\n",
      "warning.  37  xmls are missing\n",
      "(0.5171285184733778, 0.25826771653543307, 0.7372060857538036, 0.38252444603929314)\n",
      "  test HERIDAL\n",
      "(0.48281388773319944, 0.42857142857142855, 0.6231454005934718, 0.5078597339782345)\n"
     ]
    }
   ],
   "source": [
    "print('mAp@0.5, Precision, Recall, F1')\n",
    "print('  train LADD')\n",
    "targets, preds = get_targets_and_preds(ladd_train_img, LADD_PATH)\n",
    "print(evaluate_res(targets, preds))\n",
    "print('  test LADD')\n",
    "targets, preds = get_targets_and_preds(ladd_test_img, LADD_PATH)\n",
    "print(evaluate_res(targets, preds))\n",
    "print('  train HERIAL')\n",
    "targets, preds = get_targets_and_preds(heridal_train_img,HERIDAL_PATH)\n",
    "print(evaluate_res(targets, preds))\n",
    "targets, preds = get_targets_and_preds(heridal_test_img,HERIDAL_PATH)\n",
    "print('  test HERIDAL')\n",
    "print(evaluate_res(targets, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e828348d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5bc5b443a3624a5fc3c89e6c5ef6facc856f2601421ec01dcd67b6b363ab748a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('lacmus')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
