{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "Comparing inference times for keras_retinanet with different backbones and image sizes, on CPU and GPU <br>\n",
    "The measurements were run on the hardware: <br>\n",
    "<b>CPU</b>: Intel® Core™ i9-9880H CPU @ 2.30GHz × 16, 16 Gb RAM <br>\n",
    "<b>GPU</b>: GeForce RTX 2080 with Max-Q Design, 8Gb Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not to scroll down long page - results here\n",
    "The number in brackets shows inference time relatively to resnet50 backbone "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| backbone           | 1333x800       |  2000x1500      |  3000x2250     |  4000x3000       |\n",
    "| -------------------| -------------- |-----------------|----------------|------------------|\n",
    "| resnet50           |  0.662 (1x)    |   2.171 (1x)    |  5.055 (1x)    |   9.967 (1x)     | \n",
    "| mobilenet128       |  0.364 (0.55x) |   1.140 (0.53x) |  2.678 (0.53x) |   4.767 (0.48x)  |\n",
    "| mobilenet224       |  0.372 (0.56x) |   3.323 (1.53x) |  2.641 (0.52x) |   4.708 (0.47x)  |\n",
    "| mobilenetv3_small  |  0.434 (0.65x) |   1.379 (0.64x) |  3.565 (0.71x) |   5.869 (0.59x)  |\n",
    "| EfficientNetB0     |  0.868 (1.31x) |   2.959 (1.36x) | 11.656 (2.31x) |  12.571 (1.26x)  |\n",
    "| EfficientNetB1     |  1.117 (1.78x) |   3.779 (1.74x) |  9.125 (1.81x) |  16.296 (1.63x)  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also some smaller sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| backbone           |   224x224      |   500x375       |  1000x750      |  \n",
    "| -------------------| -------------- |-----------------|----------------|\n",
    "| resnet50           |  0.042 (1x)    |   0.134 (1x)    |  0.544 (1x)    |\n",
    "| mobilenet128       |  0.026 (0.62x) |   0.082 (0.61x) |  0.285 (0.52x) |\n",
    "| mobilenetv3_small  |  0.037 (0.88x) |   0.097 (0.72x) |  0.336 (0.62x) |\n",
    "| EfficientNetB0     |  0.055 (1.31x) |   0.166 (1.24x) |  0.671 (1.23x) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| backbone           | 1333x800       |  2000x1500      |  3000x2250     |  4000x3000       |\n",
    "| -------------------| -------------- |-----------------|----------------|------------------|\n",
    "| resnet50           |  0.094 (1x)    |   0.230 (1x)    |  0.519 (1x)    |   0.820 (1x)     | \n",
    "| mobilenet128       |  0.071 (0.75x) |   0.112 (0.49x) |  0.259 (0.45x) |   0.448 (0.55x)  |\n",
    "| mobilenet224       |  0.065 (0.69x) |   0.106 (0.46x) |  0.234 (0.45x) |   0.420 (0.51x)  |\n",
    "| mobilenetv3_small  |  0.077 (0.82x) |   0.129 (0.56x) |  0.282 (0.54x) |   0.475 (0.58x)  |\n",
    "| EfficientNetB0     |  0.084 (0.89x) |   0.195 (0.85x) |  0.439 (0.85x) |   0.779 (0.95x)  |\n",
    "| EfficientNetB1     |  0.088 (0.94x) |   0.243 (1.05x) |  0.535 (1.03x) |   0.940 (1.15x)  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large sizes with similar to resnet50 inference time (CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| backbone           | Size       |  Inference time | \n",
    "| -------------------| -----------|-----------------|\n",
    "| resnet50           |  1333x800  |   0.662         |\n",
    "| mobilenet128       |  1792x1076 |   0.667         |\n",
    "| mobilenet224       |  1716x1030 |   0.615         |\n",
    "| mobilenetv3_small  |  1635x981  |   0.661         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments code sources/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import progressbar\n",
    "import random\n",
    "import time\n",
    "# need keras_retinanet be installed in the system/virtualenv\n",
    "# for instance, by running 'pip install . --user' in lacmus project directory\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.preprocessing.pascal_voc import PascalVocGenerator\n",
    "from keras_retinanet.utils.gpu import setup_gpu\n",
    "from keras_retinanet import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_processing_time(model, generator, samples_count=100):\n",
    "    inference_time = 0.0\n",
    "    # time for loading, preprocessing, resizing etc. \n",
    "    accessory_time = 0.0\n",
    "    \n",
    "    # warm up\n",
    "    image = generator.load_image(0)\n",
    "    for i in range(3):\n",
    "        boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    \n",
    "    #run and measure\n",
    "    for i in progressbar.progressbar(range(samples_count)):\n",
    "        start = time.time()\n",
    "        image_index = random.randint(0, generator.size() - 1)\n",
    "        image = generator.load_image(image_index) \n",
    "        image = generator.preprocess_image(image)\n",
    "        #image, scale = generator.resize_image(image)\n",
    "        scale = 1.0\n",
    "        accessory_end = time.time()\n",
    "        accessory_time += accessory_end - start\n",
    "        \n",
    "        # process image\n",
    "        boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "        inference_end = time.time()\n",
    "        inference_time += inference_end - accessory_end\n",
    "        \n",
    "        # correct for image scale\n",
    "        boxes /= scale\n",
    "        accessory_time += time.time() - inference_end\n",
    "        \n",
    "    return inference_time / samples_count, accessory_time / samples_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../data/laddv4/full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(backbone_name, num_classes=1):\n",
    "    backbone_factory = models.backbone(backbone_name)\n",
    "    model = backbone_factory.retinanet(num_classes)\n",
    "    return models.convert_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [\n",
    "    (1333, 800),\n",
    "    (2000, 1500),\n",
    "    (3000, 2250),\n",
    "    (4000, 3000)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kseniia/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_1:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_2:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_3:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_4:0' shape=(9, 4) dtype=float32> anchors\n",
      "WARNING:tensorflow:From /home/kseniia/.local/lib/python3.7/site-packages/keras_retinanet/backend/tensorflow_backend.py:104: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/kseniia/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:32 Time:  0:01:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 1333x800 0.6628084802627563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:04:04 Time:  0:04:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 2000x1500 2.1718873810768127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:08:53 Time:  0:08:53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 3000x2250 5.055593535900116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:17:05 Time:  0:17:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 4000x3000 9.969695029258729\n"
     ]
    }
   ],
   "source": [
    "backbone = 'resnet50'\n",
    "model = create_model(backbone)\n",
    "for (max_side, min_side) in sizes:\n",
    "        generator = PascalVocGenerator(dataset_path, 'trainval', image_min_side=min_side, image_max_side=max_side)\n",
    "        inference, _ = measure_processing_time(model, generator)\n",
    "        print(backbone, str(max_side) + 'x' + str(min_side), inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_backbones = [\n",
    "    'mobilenet128_0.1',\n",
    "    'mobilenet224_0.1',\n",
    "    'mobilenet_v3_small'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable_5:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_6:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_7:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_8:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_9:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:03 Time:  0:01:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet128_0.1 1333x800 0.3642017483711243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:02:21 Time:  0:02:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet128_0.1 2000x1500 1.1396586179733277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:04:56 Time:  0:04:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet128_0.1 3000x2250 2.67762978553772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:08:26 Time:  0:08:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet128_0.1 4000x3000 4.766540586948395\n",
      "tracking <tf.Variable 'Variable_10:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_11:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_12:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_13:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_14:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:03 Time:  0:01:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet224_0.1 1333x800 0.3723181390762329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:13:31 Time:  0:13:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet224_0.1 2000x1500 7.838997864723206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:04:50 Time:  0:04:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet224_0.1 3000x2250 2.640888912677765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:08:18 Time:  0:08:18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet224_0.1 4000x3000 4.70863573551178\n",
      "tracking <tf.Variable 'Variable_15:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_16:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_17:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_18:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_19:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:08 Time:  0:01:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v3_small 1333x800 0.43451151371002195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:02:43 Time:  0:02:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v3_small 2000x1500 1.3799791264533996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:06:22 Time:  0:06:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v3_small 3000x2250 3.5652736115455625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:10:16 Time:  0:10:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v3_small 4000x3000 5.869212965965271\n"
     ]
    }
   ],
   "source": [
    "for backbone in mobile_backbones:\n",
    "    model = create_model(backbone)\n",
    "    for (max_side, min_side) in sizes:\n",
    "        generator = PascalVocGenerator(dataset_path, 'trainval', image_min_side=min_side, image_max_side=max_side)\n",
    "        inference, _ = measure_processing_time(model, generator)\n",
    "        print(backbone, str(max_side) + 'x' + str(min_side), inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_backbones = [\n",
    "    'EfficientNetB0',\n",
    "    'EfficientNetB1',\n",
    "    #'EfficientNetB2',\n",
    "    #'EfficientNetB3',\n",
    "    'EfficientNetB4',\n",
    "    #'EfficientNetB5',\n",
    "    #'EfficientNetB6',\n",
    "    'EfficientNetB7'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable_20:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_21:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_22:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_23:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_24:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:52 Time:  0:01:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB0 1333x800 0.8687555909156799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:05:22 Time:  0:05:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB0 2000x1500 2.959630126953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:19:53 Time:  0:19:53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB0 3000x2250 11.656407475471497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:21:26 Time:  0:21:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB0 4000x3000 12.571136150360108\n",
      "tracking <tf.Variable 'Variable_25:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_26:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_27:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_28:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_29:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:02:17 Time:  0:02:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB1 1333x800 1.1175025749206542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:06:44 Time:  0:06:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB1 2000x1500 3.779855136871338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:15:39 Time:  0:15:39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB1 3000x2250 9.125654451847076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:27:39 Time:  0:27:39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB1 4000x3000 16.296377265453337\n",
      "tracking <tf.Variable 'Variable_30:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_31:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_32:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_33:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_34:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:03:45 Time:  0:03:45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB4 1333x800 1.9716568541526795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6% (6 of 100) |#                       | Elapsed Time: 0:00:38 ETA:   0:08:42"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-07684f144739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_side\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_side\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPascalVocGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trainval'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_min_side\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_side\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_max_side\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_side\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0minference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasure_processing_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_side\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'x'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_side\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6ba639b8328f>\u001b[0m in \u001b[0;36mmeasure_processing_time\u001b[0;34m(model, generator, samples_count)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# process image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0minference_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0minference_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minference_end\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maccessory_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1578\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1580\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1581\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lacmus/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/envs/lacmus/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for backbone in efficientnet_backbones:\n",
    "    model = create_model(backbone)\n",
    "    for (max_side, min_side) in sizes:\n",
    "        generator = PascalVocGenerator(dataset_path, 'trainval', image_min_side=min_side, image_max_side=max_side)\n",
    "        inference, _ = measure_processing_time(model, generator)\n",
    "        print(backbone, str(max_side) + 'x' + str(min_side), inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun some strange result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (20 of 20) |########################| Elapsed Time: 0:01:13 Time:  0:01:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet224_0.1 2000x1500 3.3226078152656555\n"
     ]
    }
   ],
   "source": [
    "backbone = 'mobilenet224_0.1'\n",
    "model = create_model(backbone)\n",
    "generator = PascalVocGenerator(dataset_path, 'trainval', image_min_side=1500, image_max_side=2000)\n",
    "\n",
    "inference, _ = measure_processing_time(model, generator, samples_count=20)\n",
    "print(backbone, str(max_side) + 'x' + str(min_side), inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some smaller sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_sizes = [\n",
    "    (224, 224),\n",
    "    (500, 375),\n",
    "    (1000, 750)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbones = [\n",
    "    'resnet50',\n",
    "    'mobilenet128_0.1',\n",
    "    'mobilenet_v3_small',\n",
    "    'EfficientNetB0'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable_60:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_61:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_62:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_63:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_64:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:26 Time:  0:00:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 224x224 0.04232275009155274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:37 Time:  0:00:37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 500x375 0.13475305080413819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:20 Time:  0:01:20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 1000x750 0.544783263206482\n",
      "tracking <tf.Variable 'Variable_65:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_66:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_67:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_68:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_69:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:25 Time:  0:00:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet128_0.1 224x224 0.026973366737365723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:31 Time:  0:00:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet128_0.1 500x375 0.08248742818832397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:52 Time:  0:00:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet128_0.1 1000x750 0.2859938931465149\n",
      "tracking <tf.Variable 'Variable_70:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_71:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_72:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_73:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_74:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:27 Time:  0:00:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v3_small 224x224 0.03709912061691284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:34 Time:  0:00:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v3_small 500x375 0.09725175619125366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:58 Time:  0:00:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v3_small 1000x750 0.33656031847000123\n",
      "tracking <tf.Variable 'Variable_75:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_76:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_77:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_78:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_79:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:30 Time:  0:00:30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB0 224x224 0.05594579219818115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:42 Time:  0:00:42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB0 500x375 0.1666136837005615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:33 Time:  0:01:33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB0 1000x750 0.6717886352539062\n"
     ]
    }
   ],
   "source": [
    "for backbone in backbones:\n",
    "    model = create_model(backbone)\n",
    "    for (max_side, min_side) in small_sizes:\n",
    "        generator = PascalVocGenerator(dataset_path, 'trainval', image_min_side=min_side, image_max_side=max_side)\n",
    "        inference, _ = measure_processing_time(model, generator)\n",
    "        print(backbone, str(max_side) + 'x' + str(min_side), inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kseniia/.local/lib/python3.7/site-packages/keras_retinanet/utils/gpu.py:53: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kseniia/.local/lib/python3.7/site-packages/keras_retinanet/utils/gpu.py:55: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kseniia/.local/lib/python3.7/site-packages/keras_retinanet/utils/gpu.py:55: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "setup_gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kseniia/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_1:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_2:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_3:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_4:0' shape=(9, 4) dtype=float32> anchors\n",
      "WARNING:tensorflow:From /home/kseniia/.local/lib/python3.7/site-packages/keras_retinanet/backend/tensorflow_backend.py:104: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/kseniia/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:36 Time:  0:00:36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 1333x800 0.09466996431350708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:51 Time:  0:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 2000x1500 0.23067954540252686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:17 Time:  0:01:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 3000x2250 0.5190374398231506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:51 Time:  0:01:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 4000x3000 0.8200269746780395\n"
     ]
    }
   ],
   "source": [
    "backbone = 'resnet50'\n",
    "model = create_model(backbone)\n",
    "for (max_side, min_side) in sizes:\n",
    "        generator = PascalVocGenerator(dataset_path, 'trainval', image_min_side=min_side, image_max_side=max_side)\n",
    "        inference, _ = measure_processing_time(model, generator)\n",
    "        print(backbone, str(max_side) + 'x' + str(min_side), inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_backbones = [\n",
    "    'mobilenet128_0.1',\n",
    "    'mobilenet224_0.1',\n",
    "    'mobilenet_v3_small'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable_5:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_6:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_7:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_8:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_9:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:33 Time:  0:00:33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet128_0.1 1333x800 0.0714805269241333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:38 Time:  0:00:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet128_0.1 2000x1500 0.11212804794311523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:54 Time:  0:00:54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet128_0.1 3000x2250 0.25909081935882566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:13 Time:  0:01:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet128_0.1 4000x3000 0.44818278789520266\n",
      "tracking <tf.Variable 'Variable_10:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_11:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_12:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_13:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_14:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:32 Time:  0:00:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet224_0.1 1333x800 0.0659174394607544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:38 Time:  0:00:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet224_0.1 2000x1500 0.10697633743286133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:51 Time:  0:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet224_0.1 3000x2250 0.23436393737792968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:10 Time:  0:01:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet224_0.1 4000x3000 0.42085651636123655\n",
      "tracking <tf.Variable 'Variable_15:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_16:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_17:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_18:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_19:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:33 Time:  0:00:33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v3_small 1333x800 0.07704132795333862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:41 Time:  0:00:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v3_small 2000x1500 0.129308979511261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:56 Time:  0:00:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v3_small 3000x2250 0.2826223611831665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:14 Time:  0:01:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v3_small 4000x3000 0.47521668434143066\n"
     ]
    }
   ],
   "source": [
    "for backbone in mobile_backbones:\n",
    "    model = create_model(backbone)\n",
    "    for (max_side, min_side) in sizes:\n",
    "        generator = PascalVocGenerator(dataset_path, 'trainval', image_min_side=min_side, image_max_side=max_side)\n",
    "        inference, _ = measure_processing_time(model, generator)\n",
    "        print(backbone, str(max_side) + 'x' + str(min_side), inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_backbones = [\n",
    "    'EfficientNetB0',\n",
    "    'EfficientNetB1',\n",
    "    'EfficientNetB2',\n",
    "    'EfficientNetB3',\n",
    "    'EfficientNetB4',\n",
    "    'EfficientNetB5',\n",
    "    'EfficientNetB6',\n",
    "    'EfficientNetB7'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable_20:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_21:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_22:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_23:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_24:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:34 Time:  0:00:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB0 1333x800 0.08422770500183105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:47 Time:  0:00:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB0 2000x1500 0.1957192587852478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:11 Time:  0:01:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB0 3000x2250 0.43989492654800416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:46 Time:  0:01:46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB0 4000x3000 0.7795923185348511\n",
      "tracking <tf.Variable 'Variable_25:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_26:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_27:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_28:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_29:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:35 Time:  0:00:35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB1 1333x800 0.08809706449508667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:52 Time:  0:00:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB1 2000x1500 0.24392809867858886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:20 Time:  0:01:20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB1 3000x2250 0.5353184771537781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:02:02 Time:  0:02:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB1 4000x3000 0.9409803867340087\n",
      "tracking <tf.Variable 'Variable_30:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_31:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_32:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_33:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_34:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:36 Time:  0:00:36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB2 1333x800 0.09191283464431763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:54 Time:  0:00:54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB2 2000x1500 0.2640200686454773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:23 Time:  0:01:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB2 3000x2250 0.5759849405288696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:02:10 Time:  0:02:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB2 4000x3000 1.02139301776886\n",
      "tracking <tf.Variable 'Variable_35:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_36:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_37:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_38:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_39:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:35 Time:  0:00:35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB3 1333x800 0.10080732583999634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:58 Time:  0:00:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB3 2000x1500 0.2978340244293213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:33 Time:  0:01:33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB3 3000x2250 0.6732856345176697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:02:25 Time:  0:02:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB3 4000x3000 1.1714683508872985\n",
      "tracking <tf.Variable 'Variable_40:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_41:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_42:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_43:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_44:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:38 Time:  0:00:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB4 1333x800 0.12273181915283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:03 Time:  0:01:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB4 2000x1500 0.3567672824859619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:47 Time:  0:01:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB4 3000x2250 0.8189979839324951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74% (74 of 100) |#################      | Elapsed Time: 0:02:04 ETA:   0:00:47"
     ]
    }
   ],
   "source": [
    "for backbone in efficientnet_backbones:\n",
    "    model = create_model(backbone)\n",
    "    for (max_side, min_side) in sizes:\n",
    "        generator = PascalVocGenerator(dataset_path, 'trainval', image_min_side=min_side, image_max_side=max_side)\n",
    "        inference, _ = measure_processing_time(model, generator)\n",
    "        print(backbone, str(max_side) + 'x' + str(min_side), inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to find larger sizes that takes inference time as 1333x800 for resnet50 backbone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_gpu('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = create_model('resnet50')\n",
    "mobilenet128 = create_model('mobilenet128_0.1')\n",
    "mobilenet224 = create_model('mobilenet224_0.1')\n",
    "mobilenetv3 = create_model('mobilenet_v3_small') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relatively_increased_size(acc_samples, width=1333, height=800):\n",
    "    avg = sum(acc_samples) / len(acc_samples)\n",
    "    square_increased = width * height * (1.0 / avg)\n",
    "    square_original = width * height\n",
    "    relative = square_increased / square_original\n",
    "    return width * relative**0.5, height * relative**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mobilenet128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792.9769331741936 1076.0551736979407\n"
     ]
    }
   ],
   "source": [
    "m128_acc = [0.55, 0.53, 0.53, 0.48, 0.62, 0.61, 0.52, 0.55, 0.45, 0.49, 0.75]\n",
    "new_width, new_height = get_relatively_increased_size(m128_acc)\n",
    "print(new_width, new_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kseniia/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:33 Time:  0:01:33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6672049713134766\n"
     ]
    }
   ],
   "source": [
    "generator = PascalVocGenerator(dataset_path, 'trainval', image_min_side=new_height, image_max_side=new_width)\n",
    "inference128, _ = measure_processing_time(mobilenet128, generator)\n",
    "print(inference128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mobilenet224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843.4808338302444 1106.3650915710393\n"
     ]
    }
   ],
   "source": [
    "m224_acc = [0.56, 0.52, 0.47, 0.69, 0.46, 0.45, 0.51]\n",
    "new_width, new_height = get_relatively_increased_size(m224_acc)\n",
    "print(new_width, new_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:39 Time:  0:01:39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7177152252197265\n"
     ]
    }
   ],
   "source": [
    "generator = PascalVocGenerator(dataset_path, 'trainval', image_min_side=new_height, image_max_side=new_width)\n",
    "inference224, _ = measure_processing_time(mobilenet224, generator)\n",
    "print(inference224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:36 Time:  0:01:36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6885157752037049\n"
     ]
    }
   ],
   "source": [
    "new_width *= 0.99\n",
    "new_height *= 0.99\n",
    "generator = PascalVocGenerator(dataset_path, 'trainval', image_min_side=new_height, image_max_side=new_width)\n",
    "inference224, _ = measure_processing_time(mobilenet224, generator)\n",
    "print(inference224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:30 Time:  0:01:30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6157496452331543\n"
     ]
    }
   ],
   "source": [
    "new_width *= 0.95\n",
    "new_height *= 0.95\n",
    "generator = PascalVocGenerator(dataset_path, 'trainval', image_min_side=new_height, image_max_side=new_width)\n",
    "inference224, _ = measure_processing_time(mobilenet224, generator)\n",
    "print(inference224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1716.4557869751711 1030.1310049363367\n"
     ]
    }
   ],
   "source": [
    "print(new_width, new_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mobilenetv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635.1884223142567 981.3583929868008\n"
     ]
    }
   ],
   "source": [
    "mv3_acc = [0.65, 0.64, 0.71, 0.59, 0.88, 0.72, 0.62, 0.82, 0.56, 0.54, 0.58]\n",
    "new_width, new_height = get_relatively_increased_size(mv3_acc)\n",
    "print(new_width, new_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:01:33 Time:  0:01:33\n"
     ]
    }
   ],
   "source": [
    "generator = PascalVocGenerator(dataset_path, 'trainval', image_min_side=new_height, image_max_side=new_width)\n",
    "inferencev3, _ = measure_processing_time(mobilenetv3, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6613560914993286\n"
     ]
    }
   ],
   "source": [
    "print(inferencev3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
