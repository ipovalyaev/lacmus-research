{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f45ddd5-7de9-4bde-8a29-09a26d81c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models.detection.retinanet import RetinaNet\n",
    "import  torchvision.transforms.functional as F\n",
    "\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "import xml.etree.ElementTree as ET\n",
    "import collections\n",
    "from torchvision.datasets.voc import VisionDataset\n",
    "\n",
    "from functions import *\n",
    "from functions_torch import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd7e473-6220-4f7e-ac6b-c5736a3457e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['target_size']=(2000,1500)\n",
    "params['batch_size'] = 1\n",
    "params['lr'] = 0.001\n",
    "\n",
    "voc_root = '/app/host/lacmus/dataset/full_lacmus_ds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da6f2ee2-33f3-4296-9e6e-4af7f364466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reworked class from pytorch (see https://pytorch.org/vision/0.8/_modules/torchvision/datasets/voc.html#VOCDetection)\n",
    "\n",
    "class LADDDataSET(torchvision.datasets.VisionDataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            image_set: str,\n",
    "            transforms: Optional[Callable] = None):     \n",
    "        super(LADDDataSET, self).__init__(root, transforms=transforms)\n",
    "        self.image_set = image_set\n",
    "\n",
    "        voc_root = root\n",
    "        image_dir = os.path.join(voc_root, 'JPEGImages')\n",
    "        annotation_dir = os.path.join(voc_root, 'Annotations')\n",
    "\n",
    "        if not os.path.isdir(voc_root):\n",
    "            raise RuntimeError('Dataset not found or corrupted.')\n",
    "\n",
    "        splits_dir = os.path.join(voc_root, 'ImageSets/Main')\n",
    "        split_f = os.path.join(splits_dir, image_set.rstrip('\\n') + '.txt')\n",
    "\n",
    "        with open(os.path.join(split_f), \"r\") as f:\n",
    "            file_names = [x.strip() for x in f.readlines()]\n",
    "\n",
    "        self.images = [os.path.join(image_dir, x + \".jpg\") for x in file_names]\n",
    "        self.annotations = [os.path.join(annotation_dir, x + \".xml\") for x in file_names]\n",
    "        assert (len(self.images) == len(self.annotations))\n",
    "        \n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is a dictionary of the XML tree.\n",
    "        \"\"\"\n",
    "        img = Image.open(self.images[index]).convert('RGB')\n",
    "        description = LADDDataSET.parse_voc_xml(\n",
    "            ET.parse(self.annotations[index]).getroot())\n",
    "\n",
    "        # get bounding box coordinates \n",
    "        num_objs = len(description['annotation']['object'])\n",
    "        boxes = []\n",
    "        for l in description['annotation']['object']:\n",
    "            bb = l['bndbox']\n",
    "            boxes.append([int(bb['xmin']), int(bb['ymin']), int(bb['xmax']), int(bb['ymax'])])\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)         # there is only one class            \n",
    "        target[\"labels\"] = labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "    \n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_voc_xml(node: ET.Element) -> Dict[str, Any]:\n",
    "        voc_dict: Dict[str, Any] = {}\n",
    "        children = list(node)\n",
    "        if children:\n",
    "            def_dic: Dict[str, Any] = collections.defaultdict(list)\n",
    "            for dc in map(LADDDataSET.parse_voc_xml, children):\n",
    "                for ind, v in dc.items():\n",
    "                    def_dic[ind].append(v)\n",
    "            if node.tag == 'annotation':\n",
    "                def_dic['object'] = [def_dic['object']]\n",
    "            voc_dict = {\n",
    "                node.tag:\n",
    "                    {ind: v[0] if len(v) == 1 else v\n",
    "                     for ind, v in def_dic.items()}\n",
    "            }\n",
    "        if node.text:\n",
    "            text = node.text.strip()\n",
    "            if not children:\n",
    "                voc_dict[node.tag] = text\n",
    "        return voc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e17d1c-0cdf-4c95-9622-fba7f3022ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images 1220  non empty: 1180\n"
     ]
    }
   ],
   "source": [
    "# Pytorch implemenation of retinanet doesn't supports train on Images without any objects (which, probably need to be fixed)\n",
    "# see https://github.com/pytorch/vision/blob/master/torchvision/models/detection/retinanet.py#L475\n",
    "# As a temporary solution, yet, we just filtering out empty images\n",
    "\n",
    "splits_dir = os.path.join(voc_root, 'ImageSets/Main') \n",
    "annotation_dir = os.path.join(voc_root, 'Annotations')\n",
    "\n",
    "with open(os.path.join(splits_dir,'train.txt'), \"r\") as f:\n",
    "    file_names = [x.strip() for x in f.readlines()]\n",
    "\n",
    "non_empty = []\n",
    "for a in file_names:\n",
    "    description = LADDDataSET.parse_voc_xml(\n",
    "        ET.parse(os.path.join(annotation_dir, a + \".xml\")).getroot()\n",
    "    )\n",
    "    num_objs = len(description['annotation']['object'])\n",
    "    if num_objs > 0:\n",
    "        non_empty.append(a+'\\n')\n",
    "        \n",
    "with open(os.path.join(splits_dir,'train_non_empty.txt'), \"w\") as f:\n",
    "    f.writelines(non_empty)\n",
    "\n",
    "print('Total images '+str(len(file_names)), ' non empty: '+str(len(non_empty)))\n",
    "                                                \n",
    "                                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecd78b6f-b80d-4b32-a00f-7e558ff2c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test DS\n",
    "# im_idx = 99\n",
    "\n",
    "# dataset = LADDDataSET('/app/host/lacmus/dataset/full_lacmus_ds','test',get_transform(train=True,target_size=params['target_size'])) \n",
    "# (image,target) = dataset[im_idx] \n",
    "# im = F.to_pil_image(image)\n",
    "# draw = ImageDraw.Draw(im)\n",
    "\n",
    "# for bb in target['boxes']:\n",
    "#     draw.line([(bb[0], bb[1]), (bb[0], bb[3]), (bb[2], bb[3]),\n",
    "#                (bb[2], bb[1]), (bb[0], bb[1])], width=4, fill=(255, 0, 0))\n",
    "\n",
    "# im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "502b74f2-3125-488e-8396-71806afa56d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = LADDDataSET(voc_root,'train_non_empty',get_transform(train=True,target_size=params['target_size'])) \n",
    "dataset_val = LADDDataSET(voc_root,'val',get_transform(train=False,target_size=params['target_size'])) \n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=params['batch_size'], shuffle=True, num_workers=4\n",
    "     ,collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "    dataset_val, batch_size=1, shuffle=False, num_workers=4\n",
    "     ,collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8232f676-a422-4141-ae97-2ca0162a0426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=False, num_classes=2, pretrained_backbone=True, \n",
    "                                                           min_size=params['target_size'][0], max_size = params['target_size'][1],\n",
    "                                                           trainable_backbone_layers = 0)\n",
    "# Nees to define pretrained_backbone to use trainable_backbone_layers, otherwise it's ignored\n",
    "model.load_state_dict(torch.load('/app/host/lacmus/weights/resnet50_SDD_epoch_8.pth'), strict=False)\n",
    "\n",
    "# the computation device\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=params['lr'], momentum=0.9, weight_decay=0.0005) \n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8e5f949-d04c-4427-9606-16794545f1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [   0/1180]  eta: 0:32:32  lr: 0.000002  loss: 1.2257 (1.2257)  classification: 0.5576 (0.5576)  bbox_regression: 0.6681 (0.6681)  time: 1.6548  data: 1.3800  max mem: 1003\n",
      "Epoch: [0]  [ 100/1180]  eta: 0:05:10  lr: 0.000102  loss: 1.2374 (1.7143)  classification: 0.5661 (0.8599)  bbox_regression: 0.6505 (0.8544)  time: 0.2843  data: 0.0455  max mem: 1115\n",
      "Epoch: [0]  [ 200/1180]  eta: 0:04:33  lr: 0.000202  loss: 1.0343 (1.4716)  classification: 0.3874 (0.7200)  bbox_regression: 0.5966 (0.7516)  time: 0.2716  data: 0.0321  max mem: 1115\n",
      "Epoch: [0]  [ 300/1180]  eta: 0:04:08  lr: 0.000302  loss: 1.1435 (1.3629)  classification: 0.4662 (0.6486)  bbox_regression: 0.6166 (0.7143)  time: 0.3007  data: 0.0615  max mem: 1115\n",
      "Epoch: [0]  [ 400/1180]  eta: 0:03:40  lr: 0.000402  loss: 1.0051 (1.2898)  classification: 0.3424 (0.5993)  bbox_regression: 0.5721 (0.6904)  time: 0.2744  data: 0.0267  max mem: 1115\n",
      "Epoch: [0]  [ 500/1180]  eta: 0:03:11  lr: 0.000501  loss: 0.8881 (1.2362)  classification: 0.3536 (0.5679)  bbox_regression: 0.5350 (0.6683)  time: 0.2837  data: 0.0363  max mem: 1115\n",
      "Epoch: [0]  [ 600/1180]  eta: 0:02:42  lr: 0.000601  loss: 0.9718 (1.2053)  classification: 0.4046 (0.5530)  bbox_regression: 0.5819 (0.6523)  time: 0.2681  data: 0.0154  max mem: 2864\n",
      "Epoch: [0]  [ 700/1180]  eta: 0:02:14  lr: 0.000701  loss: 0.8532 (1.1751)  classification: 0.3028 (0.5361)  bbox_regression: 0.4860 (0.6391)  time: 0.2943  data: 0.0447  max mem: 4559\n",
      "Epoch: [0]  [ 800/1180]  eta: 0:01:47  lr: 0.000801  loss: 0.9677 (1.1550)  classification: 0.4143 (0.5265)  bbox_regression: 0.5567 (0.6284)  time: 0.2758  data: 0.0283  max mem: 4559\n",
      "Epoch: [0]  [ 900/1180]  eta: 0:01:18  lr: 0.000901  loss: 0.7266 (1.1247)  classification: 0.3038 (0.5076)  bbox_regression: 0.4371 (0.6171)  time: 0.2847  data: 0.0373  max mem: 4559\n",
      "Epoch: [0]  [1000/1180]  eta: 0:00:50  lr: 0.001000  loss: 0.7770 (1.1026)  classification: 0.3124 (0.4970)  bbox_regression: 0.4513 (0.6056)  time: 0.2661  data: 0.0194  max mem: 4559\n",
      "Epoch: [0]  [1100/1180]  eta: 0:00:22  lr: 0.001000  loss: 0.9463 (1.0870)  classification: 0.3601 (0.4886)  bbox_regression: 0.5265 (0.5984)  time: 0.2804  data: 0.0347  max mem: 4559\n",
      "Epoch: [0]  [1179/1180]  eta: 0:00:00  lr: 0.001000  loss: 0.7803 (1.0720)  classification: 0.3305 (0.4817)  bbox_regression: 0.4424 (0.5904)  time: 0.2600  data: 0.0180  max mem: 4559\n",
      "Epoch: [0] Total time: 0:05:32 (0.2814 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.5642258476423171\n",
      "0.34384041035143587\n",
      "Epoch Done\n",
      "Epoch: [1]  [   0/1180]  eta: 0:34:28  lr: 0.001000  loss: 0.6565 (0.6565)  classification: 0.3245 (0.3245)  bbox_regression: 0.3320 (0.3320)  time: 1.7531  data: 1.5129  max mem: 4559\n",
      "Epoch: [1]  [ 100/1180]  eta: 0:05:18  lr: 0.001000  loss: 0.7334 (0.8265)  classification: 0.3269 (0.3713)  bbox_regression: 0.3986 (0.4553)  time: 0.2768  data: 0.0275  max mem: 4559\n",
      "Epoch: [1]  [ 200/1180]  eta: 0:04:44  lr: 0.001000  loss: 0.6830 (0.8489)  classification: 0.2708 (0.3829)  bbox_regression: 0.4051 (0.4660)  time: 0.2843  data: 0.0401  max mem: 4559\n",
      "Epoch: [1]  [ 300/1180]  eta: 0:04:12  lr: 0.001000  loss: 0.8845 (0.8540)  classification: 0.3200 (0.3857)  bbox_regression: 0.4947 (0.4682)  time: 0.2758  data: 0.0258  max mem: 4559\n",
      "Epoch: [1]  [ 400/1180]  eta: 0:03:43  lr: 0.001000  loss: 0.7526 (0.8565)  classification: 0.2816 (0.3833)  bbox_regression: 0.4589 (0.4732)  time: 0.2907  data: 0.0458  max mem: 4559\n",
      "Epoch: [1]  [ 500/1180]  eta: 0:03:13  lr: 0.001000  loss: 0.6559 (0.8527)  classification: 0.2505 (0.3760)  bbox_regression: 0.3992 (0.4767)  time: 0.2891  data: 0.0380  max mem: 4559\n",
      "Epoch: [1]  [ 600/1180]  eta: 0:02:44  lr: 0.001000  loss: 0.7407 (0.8390)  classification: 0.3050 (0.3699)  bbox_regression: 0.4520 (0.4691)  time: 0.2829  data: 0.0304  max mem: 4559\n",
      "Epoch: [1]  [ 700/1180]  eta: 0:02:15  lr: 0.001000  loss: 0.7398 (0.8376)  classification: 0.2735 (0.3673)  bbox_regression: 0.3965 (0.4703)  time: 0.2736  data: 0.0230  max mem: 4559\n",
      "Epoch: [1]  [ 800/1180]  eta: 0:01:47  lr: 0.001000  loss: 0.7011 (0.8350)  classification: 0.3324 (0.3669)  bbox_regression: 0.4058 (0.4681)  time: 0.2682  data: 0.0196  max mem: 4559\n",
      "Epoch: [1]  [ 900/1180]  eta: 0:01:18  lr: 0.001000  loss: 0.7717 (0.8343)  classification: 0.3577 (0.3682)  bbox_regression: 0.4139 (0.4660)  time: 0.2854  data: 0.0350  max mem: 4559\n",
      "Epoch: [1]  [1000/1180]  eta: 0:00:50  lr: 0.001000  loss: 0.6623 (0.8303)  classification: 0.2780 (0.3665)  bbox_regression: 0.3960 (0.4638)  time: 0.2772  data: 0.0283  max mem: 4559\n",
      "Epoch: [1]  [1100/1180]  eta: 0:00:22  lr: 0.001000  loss: 0.7647 (0.8286)  classification: 0.2924 (0.3658)  bbox_regression: 0.4311 (0.4627)  time: 0.2961  data: 0.0464  max mem: 4559\n",
      "Epoch: [1]  [1179/1180]  eta: 0:00:00  lr: 0.001000  loss: 0.6615 (0.8206)  classification: 0.3034 (0.3618)  bbox_regression: 0.3905 (0.4588)  time: 0.2552  data: 0.0142  max mem: 4559\n",
      "Epoch: [1] Total time: 0:05:31 (0.2807 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.6779956099463759\n",
      "0.48780705054321205\n",
      "Epoch Done\n",
      "Epoch: [2]  [   0/1180]  eta: 0:27:14  lr: 0.001000  loss: 0.5576 (0.5576)  classification: 0.2115 (0.2115)  bbox_regression: 0.3461 (0.3461)  time: 1.3852  data: 1.1256  max mem: 4559\n",
      "Epoch: [2]  [ 100/1180]  eta: 0:05:01  lr: 0.001000  loss: 0.7237 (0.7638)  classification: 0.3487 (0.3300)  bbox_regression: 0.4281 (0.4338)  time: 0.2648  data: 0.0154  max mem: 4559\n",
      "Epoch: [2]  [ 200/1180]  eta: 0:04:36  lr: 0.001000  loss: 0.6213 (0.7841)  classification: 0.2531 (0.3449)  bbox_regression: 0.3672 (0.4392)  time: 0.2979  data: 0.0455  max mem: 4559\n",
      "Epoch: [2]  [ 300/1180]  eta: 0:04:05  lr: 0.001000  loss: 0.6452 (0.7586)  classification: 0.3153 (0.3315)  bbox_regression: 0.3400 (0.4272)  time: 0.2822  data: 0.0362  max mem: 4559\n",
      "Epoch: [2]  [ 400/1180]  eta: 0:03:39  lr: 0.001000  loss: 0.6802 (0.7575)  classification: 0.2444 (0.3330)  bbox_regression: 0.4048 (0.4245)  time: 0.2850  data: 0.0346  max mem: 4559\n",
      "Epoch: [2]  [ 500/1180]  eta: 0:03:11  lr: 0.001000  loss: 0.7824 (0.7481)  classification: 0.3718 (0.3266)  bbox_regression: 0.4013 (0.4215)  time: 0.2797  data: 0.0333  max mem: 4559\n",
      "Epoch: [2]  [ 600/1180]  eta: 0:02:43  lr: 0.001000  loss: 0.6955 (0.7400)  classification: 0.2643 (0.3214)  bbox_regression: 0.4149 (0.4186)  time: 0.2838  data: 0.0339  max mem: 4559\n",
      "Epoch: [2]  [ 700/1180]  eta: 0:02:15  lr: 0.001000  loss: 0.6816 (0.7344)  classification: 0.2781 (0.3211)  bbox_regression: 0.3511 (0.4132)  time: 0.2682  data: 0.0172  max mem: 4559\n",
      "Epoch: [2]  [ 800/1180]  eta: 0:01:47  lr: 0.001000  loss: 0.6403 (0.7294)  classification: 0.2619 (0.3178)  bbox_regression: 0.3261 (0.4117)  time: 0.2683  data: 0.0162  max mem: 4559\n",
      "Epoch: [2]  [ 900/1180]  eta: 0:01:18  lr: 0.001000  loss: 0.6380 (0.7272)  classification: 0.2529 (0.3151)  bbox_regression: 0.3947 (0.4122)  time: 0.2990  data: 0.0524  max mem: 4559\n",
      "Epoch: [2]  [1000/1180]  eta: 0:00:50  lr: 0.001000  loss: 0.6961 (0.7283)  classification: 0.3218 (0.3165)  bbox_regression: 0.3849 (0.4118)  time: 0.2793  data: 0.0318  max mem: 4559\n",
      "Epoch: [2]  [1100/1180]  eta: 0:00:22  lr: 0.001000  loss: 0.5863 (0.7286)  classification: 0.2023 (0.3160)  bbox_regression: 0.2629 (0.4126)  time: 0.2685  data: 0.0213  max mem: 4559\n",
      "Epoch: [2]  [1179/1180]  eta: 0:00:00  lr: 0.001000  loss: 0.6599 (0.7317)  classification: 0.2834 (0.3189)  bbox_regression: 0.3251 (0.4128)  time: 0.2567  data: 0.0103  max mem: 4559\n",
      "Epoch: [2] Total time: 0:05:31 (0.2811 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.7201392971446073\n",
      "0.5388223070512422\n",
      "Epoch Done\n",
      "Epoch: [3]  [   0/1180]  eta: 0:26:46  lr: 0.000100  loss: 1.3735 (1.3735)  classification: 0.7444 (0.7444)  bbox_regression: 0.6291 (0.6291)  time: 1.3616  data: 1.1225  max mem: 4559\n",
      "Epoch: [3]  [ 100/1180]  eta: 0:05:13  lr: 0.000100  loss: 0.6041 (0.6636)  classification: 0.2753 (0.2926)  bbox_regression: 0.3313 (0.3709)  time: 0.2931  data: 0.0407  max mem: 4559\n",
      "Epoch: [3]  [ 200/1180]  eta: 0:04:39  lr: 0.000100  loss: 0.5145 (0.6145)  classification: 0.2162 (0.2681)  bbox_regression: 0.2680 (0.3464)  time: 0.2746  data: 0.0258  max mem: 4559\n",
      "Epoch: [3]  [ 300/1180]  eta: 0:04:08  lr: 0.000100  loss: 0.4968 (0.6238)  classification: 0.2139 (0.2747)  bbox_regression: 0.3173 (0.3490)  time: 0.2647  data: 0.0191  max mem: 4559\n",
      "Epoch: [3]  [ 400/1180]  eta: 0:03:37  lr: 0.000100  loss: 0.5353 (0.6330)  classification: 0.1981 (0.2779)  bbox_regression: 0.3396 (0.3550)  time: 0.2806  data: 0.0321  max mem: 4559\n",
      "Epoch: [3]  [ 500/1180]  eta: 0:03:10  lr: 0.000100  loss: 0.6143 (0.6412)  classification: 0.2545 (0.2831)  bbox_regression: 0.3291 (0.3581)  time: 0.2928  data: 0.0384  max mem: 4559\n",
      "Epoch: [3]  [ 600/1180]  eta: 0:02:42  lr: 0.000100  loss: 0.5436 (0.6324)  classification: 0.2235 (0.2779)  bbox_regression: 0.2923 (0.3545)  time: 0.2752  data: 0.0262  max mem: 4559\n",
      "Epoch: [3]  [ 700/1180]  eta: 0:02:14  lr: 0.000100  loss: 0.5016 (0.6314)  classification: 0.2341 (0.2770)  bbox_regression: 0.2835 (0.3543)  time: 0.2805  data: 0.0347  max mem: 4559\n",
      "Epoch: [3]  [ 800/1180]  eta: 0:01:46  lr: 0.000100  loss: 0.4574 (0.6251)  classification: 0.2004 (0.2740)  bbox_regression: 0.2755 (0.3512)  time: 0.2776  data: 0.0285  max mem: 4559\n",
      "Epoch: [3]  [ 900/1180]  eta: 0:01:18  lr: 0.000100  loss: 0.6564 (0.6253)  classification: 0.2854 (0.2740)  bbox_regression: 0.3471 (0.3513)  time: 0.2992  data: 0.0490  max mem: 4559\n",
      "Epoch: [3]  [1000/1180]  eta: 0:00:50  lr: 0.000100  loss: 0.5480 (0.6237)  classification: 0.2278 (0.2727)  bbox_regression: 0.2997 (0.3510)  time: 0.3028  data: 0.0565  max mem: 4559\n",
      "Epoch: [3]  [1100/1180]  eta: 0:00:22  lr: 0.000100  loss: 0.4663 (0.6237)  classification: 0.1920 (0.2729)  bbox_regression: 0.2827 (0.3508)  time: 0.2797  data: 0.0304  max mem: 4559\n",
      "Epoch: [3]  [1179/1180]  eta: 0:00:00  lr: 0.000100  loss: 0.4773 (0.6225)  classification: 0.1984 (0.2713)  bbox_regression: 0.2992 (0.3511)  time: 0.2867  data: 0.0390  max mem: 4559\n",
      "Epoch: [3] Total time: 0:05:30 (0.2797 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.7718234409414945\n",
      "0.5988146608165335\n",
      "Epoch Done\n",
      "Epoch: [4]  [   0/1180]  eta: 0:27:48  lr: 0.000100  loss: 0.4894 (0.4894)  classification: 0.2109 (0.2109)  bbox_regression: 0.2784 (0.2784)  time: 1.4142  data: 1.1649  max mem: 4559\n",
      "Epoch: [4]  [ 100/1180]  eta: 0:05:19  lr: 0.000100  loss: 0.6324 (0.6077)  classification: 0.2647 (0.2639)  bbox_regression: 0.3435 (0.3438)  time: 0.2944  data: 0.0421  max mem: 4559\n",
      "Epoch: [4]  [ 200/1180]  eta: 0:04:37  lr: 0.000100  loss: 0.6114 (0.6275)  classification: 0.2455 (0.2757)  bbox_regression: 0.3177 (0.3518)  time: 0.2767  data: 0.0255  max mem: 4559\n",
      "Epoch: [4]  [ 300/1180]  eta: 0:04:09  lr: 0.000100  loss: 0.4800 (0.6131)  classification: 0.2118 (0.2675)  bbox_regression: 0.2900 (0.3456)  time: 0.2722  data: 0.0249  max mem: 4559\n",
      "Epoch: [4]  [ 400/1180]  eta: 0:03:41  lr: 0.000100  loss: 0.7417 (0.6237)  classification: 0.2727 (0.2704)  bbox_regression: 0.3469 (0.3533)  time: 0.2709  data: 0.0264  max mem: 4559\n",
      "Epoch: [4]  [ 500/1180]  eta: 0:03:11  lr: 0.000100  loss: 0.5189 (0.6112)  classification: 0.2166 (0.2662)  bbox_regression: 0.3126 (0.3450)  time: 0.2893  data: 0.0374  max mem: 4559\n",
      "Epoch: [4]  [ 600/1180]  eta: 0:02:43  lr: 0.000100  loss: 0.5259 (0.6068)  classification: 0.2229 (0.2668)  bbox_regression: 0.2852 (0.3399)  time: 0.2726  data: 0.0205  max mem: 4559\n",
      "Epoch: [4]  [ 700/1180]  eta: 0:02:15  lr: 0.000100  loss: 0.4173 (0.6067)  classification: 0.2024 (0.2683)  bbox_regression: 0.2424 (0.3384)  time: 0.2573  data: 0.0109  max mem: 4559\n",
      "Epoch: [4]  [ 800/1180]  eta: 0:01:48  lr: 0.000100  loss: 0.5648 (0.6047)  classification: 0.2169 (0.2661)  bbox_regression: 0.3136 (0.3386)  time: 0.2892  data: 0.0391  max mem: 4559\n",
      "Epoch: [4]  [ 900/1180]  eta: 0:01:19  lr: 0.000100  loss: 0.4716 (0.6025)  classification: 0.1758 (0.2654)  bbox_regression: 0.2770 (0.3371)  time: 0.2901  data: 0.0440  max mem: 4559\n",
      "Epoch: [4]  [1000/1180]  eta: 0:00:51  lr: 0.000100  loss: 0.4931 (0.6017)  classification: 0.2134 (0.2643)  bbox_regression: 0.2917 (0.3373)  time: 0.3000  data: 0.0517  max mem: 4559\n",
      "Epoch: [4]  [1100/1180]  eta: 0:00:22  lr: 0.000100  loss: 0.5537 (0.6051)  classification: 0.2266 (0.2646)  bbox_regression: 0.2908 (0.3404)  time: 0.2907  data: 0.0438  max mem: 4559\n",
      "Epoch: [4]  [1179/1180]  eta: 0:00:00  lr: 0.000100  loss: 0.5205 (0.6019)  classification: 0.2220 (0.2630)  bbox_regression: 0.3044 (0.3389)  time: 0.2681  data: 0.0244  max mem: 4559\n",
      "Epoch: [4] Total time: 0:05:34 (0.2832 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.7778939752682381\n",
      "0.6079113577882098\n",
      "Epoch Done\n",
      "Epoch: [5]  [   0/1180]  eta: 0:29:54  lr: 0.000100  loss: 0.3840 (0.3840)  classification: 0.1990 (0.1990)  bbox_regression: 0.1850 (0.1850)  time: 1.5207  data: 1.2679  max mem: 4559\n",
      "Epoch: [5]  [ 100/1180]  eta: 0:05:17  lr: 0.000100  loss: 0.5185 (0.6021)  classification: 0.2099 (0.2581)  bbox_regression: 0.3082 (0.3440)  time: 0.2844  data: 0.0346  max mem: 4559\n",
      "Epoch: [5]  [ 200/1180]  eta: 0:04:40  lr: 0.000100  loss: 0.5449 (0.6056)  classification: 0.2071 (0.2534)  bbox_regression: 0.3638 (0.3522)  time: 0.2693  data: 0.0213  max mem: 4559\n",
      "Epoch: [5]  [ 300/1180]  eta: 0:04:09  lr: 0.000100  loss: 0.5128 (0.6042)  classification: 0.2312 (0.2585)  bbox_regression: 0.3081 (0.3456)  time: 0.2623  data: 0.0140  max mem: 4559\n",
      "Epoch: [5]  [ 400/1180]  eta: 0:03:39  lr: 0.000100  loss: 0.4768 (0.5991)  classification: 0.1825 (0.2589)  bbox_regression: 0.2875 (0.3402)  time: 0.2702  data: 0.0221  max mem: 4559\n",
      "Epoch: [5]  [ 500/1180]  eta: 0:03:11  lr: 0.000100  loss: 0.4836 (0.5943)  classification: 0.2229 (0.2580)  bbox_regression: 0.3011 (0.3363)  time: 0.2750  data: 0.0229  max mem: 4559\n",
      "Epoch: [5]  [ 600/1180]  eta: 0:02:44  lr: 0.000100  loss: 0.7214 (0.5970)  classification: 0.2656 (0.2585)  bbox_regression: 0.2866 (0.3385)  time: 0.3168  data: 0.0670  max mem: 4559\n",
      "Epoch: [5]  [ 700/1180]  eta: 0:02:15  lr: 0.000100  loss: 0.6127 (0.5934)  classification: 0.2348 (0.2570)  bbox_regression: 0.3743 (0.3364)  time: 0.2866  data: 0.0365  max mem: 4559\n",
      "Epoch: [5]  [ 800/1180]  eta: 0:01:47  lr: 0.000100  loss: 0.6206 (0.5988)  classification: 0.2434 (0.2607)  bbox_regression: 0.3789 (0.3382)  time: 0.2933  data: 0.0417  max mem: 4559\n",
      "Epoch: [5]  [ 900/1180]  eta: 0:01:19  lr: 0.000100  loss: 0.6565 (0.5978)  classification: 0.3125 (0.2606)  bbox_regression: 0.3362 (0.3372)  time: 0.2817  data: 0.0359  max mem: 4559\n",
      "Epoch: [5]  [1000/1180]  eta: 0:00:50  lr: 0.000100  loss: 0.5503 (0.5951)  classification: 0.1915 (0.2592)  bbox_regression: 0.3209 (0.3359)  time: 0.3187  data: 0.0718  max mem: 4559\n",
      "Epoch: [5]  [1100/1180]  eta: 0:00:22  lr: 0.000100  loss: 0.4983 (0.5947)  classification: 0.1786 (0.2585)  bbox_regression: 0.3105 (0.3361)  time: 0.2602  data: 0.0130  max mem: 4559\n",
      "Epoch: [5]  [1179/1180]  eta: 0:00:00  lr: 0.000100  loss: 0.6078 (0.5920)  classification: 0.2346 (0.2570)  bbox_regression: 0.3421 (0.3350)  time: 0.2618  data: 0.0203  max mem: 4559\n",
      "Epoch: [5] Total time: 0:05:31 (0.2810 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.7732315278499453\n",
      "0.5919645144321808\n",
      "Epoch Done\n",
      "Epoch: [6]  [   0/1180]  eta: 0:26:34  lr: 0.000010  loss: 0.5622 (0.5622)  classification: 0.2439 (0.2439)  bbox_regression: 0.3183 (0.3183)  time: 1.3513  data: 1.1038  max mem: 4559\n",
      "Epoch: [6]  [ 100/1180]  eta: 0:05:09  lr: 0.000010  loss: 0.5628 (0.6050)  classification: 0.2531 (0.2694)  bbox_regression: 0.3231 (0.3356)  time: 0.2779  data: 0.0290  max mem: 4559\n",
      "Epoch: [6]  [ 200/1180]  eta: 0:04:34  lr: 0.000010  loss: 0.4585 (0.6148)  classification: 0.1948 (0.2743)  bbox_regression: 0.2821 (0.3405)  time: 0.2668  data: 0.0190  max mem: 4559\n",
      "Epoch: [6]  [ 300/1180]  eta: 0:04:06  lr: 0.000010  loss: 0.6151 (0.6011)  classification: 0.2583 (0.2668)  bbox_regression: 0.3269 (0.3343)  time: 0.2972  data: 0.0442  max mem: 4559\n",
      "Epoch: [6]  [ 400/1180]  eta: 0:03:38  lr: 0.000010  loss: 0.5523 (0.5976)  classification: 0.1951 (0.2646)  bbox_regression: 0.3356 (0.3331)  time: 0.2845  data: 0.0370  max mem: 4559\n",
      "Epoch: [6]  [ 500/1180]  eta: 0:03:10  lr: 0.000010  loss: 0.4686 (0.5949)  classification: 0.1900 (0.2617)  bbox_regression: 0.2637 (0.3332)  time: 0.2718  data: 0.0252  max mem: 4559\n",
      "Epoch: [6]  [ 600/1180]  eta: 0:02:42  lr: 0.000010  loss: 0.4865 (0.5863)  classification: 0.1916 (0.2592)  bbox_regression: 0.2664 (0.3271)  time: 0.2795  data: 0.0335  max mem: 4559\n",
      "Epoch: [6]  [ 700/1180]  eta: 0:02:14  lr: 0.000010  loss: 0.6032 (0.5795)  classification: 0.1698 (0.2552)  bbox_regression: 0.3213 (0.3243)  time: 0.2759  data: 0.0301  max mem: 4559\n",
      "Epoch: [6]  [ 800/1180]  eta: 0:01:46  lr: 0.000010  loss: 0.5471 (0.5800)  classification: 0.1928 (0.2555)  bbox_regression: 0.3264 (0.3245)  time: 0.2807  data: 0.0283  max mem: 4559\n",
      "Epoch: [6]  [ 900/1180]  eta: 0:01:18  lr: 0.000010  loss: 0.4739 (0.5767)  classification: 0.1762 (0.2532)  bbox_regression: 0.2680 (0.3235)  time: 0.2784  data: 0.0311  max mem: 4559\n",
      "Epoch: [6]  [1000/1180]  eta: 0:00:50  lr: 0.000010  loss: 0.4823 (0.5752)  classification: 0.2092 (0.2520)  bbox_regression: 0.3309 (0.3232)  time: 0.2770  data: 0.0331  max mem: 4559\n",
      "Epoch: [6]  [1100/1180]  eta: 0:00:22  lr: 0.000010  loss: 0.5193 (0.5759)  classification: 0.1837 (0.2516)  bbox_regression: 0.3260 (0.3243)  time: 0.2689  data: 0.0164  max mem: 4559\n",
      "Epoch: [6]  [1179/1180]  eta: 0:00:00  lr: 0.000010  loss: 0.4440 (0.5761)  classification: 0.1640 (0.2519)  bbox_regression: 0.2646 (0.3242)  time: 0.2695  data: 0.0232  max mem: 4559\n",
      "Epoch: [6] Total time: 0:05:31 (0.2806 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.7794552956967595\n",
      "0.591494123487643\n",
      "Epoch Done\n",
      "Epoch: [7]  [   0/1180]  eta: 0:28:26  lr: 0.000010  loss: 0.3202 (0.3202)  classification: 0.1088 (0.1088)  bbox_regression: 0.2115 (0.2115)  time: 1.4462  data: 1.2057  max mem: 4559\n",
      "Epoch: [7]  [ 100/1180]  eta: 0:05:15  lr: 0.000010  loss: 0.5638 (0.5830)  classification: 0.2650 (0.2551)  bbox_regression: 0.2655 (0.3279)  time: 0.2820  data: 0.0321  max mem: 4559\n",
      "Epoch: [7]  [ 200/1180]  eta: 0:04:39  lr: 0.000010  loss: 0.5248 (0.5809)  classification: 0.2045 (0.2444)  bbox_regression: 0.2854 (0.3365)  time: 0.2756  data: 0.0281  max mem: 4559\n",
      "Epoch: [7]  [ 300/1180]  eta: 0:04:09  lr: 0.000010  loss: 0.4331 (0.5810)  classification: 0.1842 (0.2449)  bbox_regression: 0.2466 (0.3361)  time: 0.2874  data: 0.0385  max mem: 4559\n",
      "Epoch: [7]  [ 400/1180]  eta: 0:03:40  lr: 0.000010  loss: 0.5149 (0.5775)  classification: 0.2374 (0.2450)  bbox_regression: 0.2790 (0.3324)  time: 0.2693  data: 0.0215  max mem: 4559\n",
      "Epoch: [7]  [ 500/1180]  eta: 0:03:12  lr: 0.000010  loss: 0.5009 (0.5726)  classification: 0.1906 (0.2442)  bbox_regression: 0.2633 (0.3285)  time: 0.2867  data: 0.0387  max mem: 4559\n",
      "Epoch: [7]  [ 600/1180]  eta: 0:02:43  lr: 0.000010  loss: 0.5218 (0.5731)  classification: 0.2114 (0.2441)  bbox_regression: 0.3479 (0.3289)  time: 0.2743  data: 0.0270  max mem: 4559\n",
      "Epoch: [7]  [ 700/1180]  eta: 0:02:15  lr: 0.000010  loss: 0.4778 (0.5725)  classification: 0.2060 (0.2435)  bbox_regression: 0.2310 (0.3291)  time: 0.2869  data: 0.0395  max mem: 4559\n",
      "Epoch: [7]  [ 800/1180]  eta: 0:01:47  lr: 0.000010  loss: 0.5614 (0.5758)  classification: 0.2176 (0.2466)  bbox_regression: 0.2932 (0.3292)  time: 0.2685  data: 0.0190  max mem: 4559\n",
      "Epoch: [7]  [ 900/1180]  eta: 0:01:18  lr: 0.000010  loss: 0.4553 (0.5763)  classification: 0.1822 (0.2478)  bbox_regression: 0.2741 (0.3284)  time: 0.2890  data: 0.0415  max mem: 4559\n",
      "Epoch: [7]  [1000/1180]  eta: 0:00:50  lr: 0.000010  loss: 0.6259 (0.5764)  classification: 0.2638 (0.2482)  bbox_regression: 0.3954 (0.3282)  time: 0.2756  data: 0.0282  max mem: 4559\n",
      "Epoch: [7]  [1100/1180]  eta: 0:00:22  lr: 0.000010  loss: 0.5576 (0.5775)  classification: 0.2027 (0.2492)  bbox_regression: 0.2703 (0.3283)  time: 0.2813  data: 0.0311  max mem: 4559\n",
      "Epoch: [7]  [1179/1180]  eta: 0:00:00  lr: 0.000010  loss: 0.4528 (0.5765)  classification: 0.1943 (0.2489)  bbox_regression: 0.2573 (0.3276)  time: 0.2834  data: 0.0351  max mem: 4559\n",
      "Epoch: [7] Total time: 0:05:34 (0.2831 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.7799630277109291\n",
      "0.6013269553769491\n",
      "Epoch Done\n",
      "Epoch: [8]  [   0/1180]  eta: 0:26:59  lr: 0.000010  loss: 0.6828 (0.6828)  classification: 0.2891 (0.2891)  bbox_regression: 0.3937 (0.3937)  time: 1.3727  data: 1.1327  max mem: 4559\n",
      "Epoch: [8]  [ 100/1180]  eta: 0:05:24  lr: 0.000010  loss: 0.4317 (0.5849)  classification: 0.1579 (0.2556)  bbox_regression: 0.2939 (0.3293)  time: 0.2825  data: 0.0314  max mem: 4559\n",
      "Epoch: [8]  [ 200/1180]  eta: 0:04:42  lr: 0.000010  loss: 0.5172 (0.5809)  classification: 0.2249 (0.2546)  bbox_regression: 0.2912 (0.3263)  time: 0.2859  data: 0.0408  max mem: 4559\n",
      "Epoch: [8]  [ 300/1180]  eta: 0:04:11  lr: 0.000010  loss: 0.3962 (0.5667)  classification: 0.1482 (0.2452)  bbox_regression: 0.2312 (0.3214)  time: 0.2733  data: 0.0248  max mem: 4559\n",
      "Epoch: [8]  [ 400/1180]  eta: 0:03:43  lr: 0.000010  loss: 0.6530 (0.5738)  classification: 0.2950 (0.2528)  bbox_regression: 0.3078 (0.3210)  time: 0.2923  data: 0.0379  max mem: 4559\n",
      "Epoch: [8]  [ 500/1180]  eta: 0:03:13  lr: 0.000010  loss: 0.5986 (0.5807)  classification: 0.2509 (0.2550)  bbox_regression: 0.3544 (0.3257)  time: 0.2765  data: 0.0255  max mem: 4559\n",
      "Epoch: [8]  [ 600/1180]  eta: 0:02:44  lr: 0.000010  loss: 0.5909 (0.5805)  classification: 0.2703 (0.2524)  bbox_regression: 0.3014 (0.3281)  time: 0.2875  data: 0.0422  max mem: 4559\n",
      "Epoch: [8]  [ 700/1180]  eta: 0:02:15  lr: 0.000010  loss: 0.5270 (0.5804)  classification: 0.2088 (0.2520)  bbox_regression: 0.2943 (0.3284)  time: 0.2957  data: 0.0438  max mem: 4559\n",
      "Epoch: [8]  [ 800/1180]  eta: 0:01:47  lr: 0.000010  loss: 0.4505 (0.5797)  classification: 0.2000 (0.2526)  bbox_regression: 0.2624 (0.3271)  time: 0.2605  data: 0.0162  max mem: 4559\n",
      "Epoch: [8]  [ 900/1180]  eta: 0:01:19  lr: 0.000010  loss: 0.4670 (0.5797)  classification: 0.1971 (0.2521)  bbox_regression: 0.2466 (0.3276)  time: 0.2902  data: 0.0392  max mem: 4559\n",
      "Epoch: [8]  [1000/1180]  eta: 0:00:50  lr: 0.000010  loss: 0.5058 (0.5754)  classification: 0.1622 (0.2503)  bbox_regression: 0.3079 (0.3251)  time: 0.2989  data: 0.0541  max mem: 4559\n",
      "Epoch: [8]  [1100/1180]  eta: 0:00:22  lr: 0.000010  loss: 0.5130 (0.5747)  classification: 0.2144 (0.2498)  bbox_regression: 0.3097 (0.3249)  time: 0.2652  data: 0.0175  max mem: 4559\n",
      "Epoch: [8]  [1179/1180]  eta: 0:00:00  lr: 0.000010  loss: 0.4628 (0.5723)  classification: 0.1933 (0.2482)  bbox_regression: 0.3093 (0.3241)  time: 0.2822  data: 0.0344  max mem: 4559\n",
      "Epoch: [8] Total time: 0:05:33 (0.2830 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.7832924012361431\n",
      "0.6062535116404703\n",
      "Epoch Done\n",
      "Epoch: [9]  [   0/1180]  eta: 0:29:52  lr: 0.000001  loss: 0.4459 (0.4459)  classification: 0.1998 (0.1998)  bbox_regression: 0.2461 (0.2461)  time: 1.5189  data: 1.2538  max mem: 4559\n",
      "Epoch: [9]  [ 100/1180]  eta: 0:05:25  lr: 0.000001  loss: 0.5100 (0.5601)  classification: 0.2276 (0.2423)  bbox_regression: 0.3097 (0.3178)  time: 0.2946  data: 0.0460  max mem: 4559\n",
      "Epoch: [9]  [ 200/1180]  eta: 0:04:42  lr: 0.000001  loss: 0.4512 (0.5563)  classification: 0.1611 (0.2426)  bbox_regression: 0.2804 (0.3137)  time: 0.2960  data: 0.0418  max mem: 4559\n",
      "Epoch: [9]  [ 300/1180]  eta: 0:04:10  lr: 0.000001  loss: 0.6767 (0.5686)  classification: 0.2900 (0.2495)  bbox_regression: 0.3522 (0.3192)  time: 0.2878  data: 0.0409  max mem: 4559\n",
      "Epoch: [9]  [ 400/1180]  eta: 0:03:41  lr: 0.000001  loss: 0.4461 (0.5753)  classification: 0.1796 (0.2491)  bbox_regression: 0.3014 (0.3262)  time: 0.2796  data: 0.0324  max mem: 4559\n",
      "Epoch: [9]  [ 500/1180]  eta: 0:03:13  lr: 0.000001  loss: 0.4211 (0.5799)  classification: 0.1962 (0.2527)  bbox_regression: 0.2513 (0.3272)  time: 0.2870  data: 0.0405  max mem: 4559\n",
      "Epoch: [9]  [ 600/1180]  eta: 0:02:44  lr: 0.000001  loss: 0.5028 (0.5768)  classification: 0.1999 (0.2509)  bbox_regression: 0.2911 (0.3259)  time: 0.2868  data: 0.0356  max mem: 4559\n",
      "Epoch: [9]  [ 700/1180]  eta: 0:02:16  lr: 0.000001  loss: 0.4924 (0.5792)  classification: 0.1795 (0.2525)  bbox_regression: 0.2599 (0.3267)  time: 0.3296  data: 0.0794  max mem: 4559\n",
      "Epoch: [9]  [ 800/1180]  eta: 0:01:47  lr: 0.000001  loss: 0.5404 (0.5739)  classification: 0.2293 (0.2504)  bbox_regression: 0.3241 (0.3234)  time: 0.2761  data: 0.0273  max mem: 4559\n",
      "Epoch: [9]  [ 900/1180]  eta: 0:01:19  lr: 0.000001  loss: 0.3604 (0.5777)  classification: 0.1825 (0.2520)  bbox_regression: 0.2001 (0.3257)  time: 0.2662  data: 0.0162  max mem: 4559\n",
      "Epoch: [9]  [1000/1180]  eta: 0:00:51  lr: 0.000001  loss: 0.5591 (0.5779)  classification: 0.1704 (0.2517)  bbox_regression: 0.3295 (0.3262)  time: 0.3036  data: 0.0570  max mem: 4559\n",
      "Epoch: [9]  [1100/1180]  eta: 0:00:22  lr: 0.000001  loss: 0.3922 (0.5726)  classification: 0.1581 (0.2487)  bbox_regression: 0.2158 (0.3239)  time: 0.3182  data: 0.0703  max mem: 4559\n",
      "Epoch: [9]  [1179/1180]  eta: 0:00:00  lr: 0.000001  loss: 0.4742 (0.5709)  classification: 0.2001 (0.2473)  bbox_regression: 0.2708 (0.3236)  time: 0.2849  data: 0.0405  max mem: 4559\n",
      "Epoch: [9] Total time: 0:05:35 (0.2845 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.7840393865744706\n",
      "0.6116921459335862\n",
      "Epoch Done\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10): # train without backbone\n",
    "\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=100)\n",
    "    print (\"Train done, evaluating.\")\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    inference_res = evaluate(model,data_loader_val)\n",
    "    print('Inference done, computing mAp : ')\n",
    "    print(evaluate_res(inference_res, iou_threshold = 0.5, score_threshold = 0.05))    \n",
    "    print(evaluate_res(inference_res, iou_threshold = 0.6, score_threshold = 0.05))\n",
    "    print('Epoch Done')\n",
    "    \n",
    "torch.save(model.state_dict(), '/app/host/lacmus/weights/resnet50_LADD_head.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df264737-5016-48af-9036-b3ad68ca73de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [   0/1180]  eta: 0:27:09  lr: 0.000002  loss: 0.4523 (0.4523)  classification: 0.2102 (0.2102)  bbox_regression: 0.2421 (0.2421)  time: 1.3806  data: 0.9362  max mem: 7286\n",
      "Epoch: [0]  [ 100/1180]  eta: 0:08:23  lr: 0.000102  loss: 0.4663 (0.5672)  classification: 0.1765 (0.2427)  bbox_regression: 0.2742 (0.3244)  time: 0.4632  data: 0.0130  max mem: 7286\n",
      "Epoch: [0]  [ 200/1180]  eta: 0:07:33  lr: 0.000202  loss: 0.6076 (0.5929)  classification: 0.2546 (0.2652)  bbox_regression: 0.3119 (0.3277)  time: 0.4587  data: 0.0131  max mem: 7286\n",
      "Epoch: [0]  [ 300/1180]  eta: 0:06:46  lr: 0.000302  loss: 0.5980 (0.6249)  classification: 0.2058 (0.2782)  bbox_regression: 0.3486 (0.3468)  time: 0.4589  data: 0.0146  max mem: 7286\n",
      "Epoch: [0]  [ 400/1180]  eta: 0:05:59  lr: 0.000402  loss: 0.6312 (0.6360)  classification: 0.2986 (0.2823)  bbox_regression: 0.3313 (0.3538)  time: 0.4575  data: 0.0139  max mem: 7286\n",
      "Epoch: [0]  [ 500/1180]  eta: 0:05:13  lr: 0.000501  loss: 0.6180 (0.6425)  classification: 0.2448 (0.2872)  bbox_regression: 0.3323 (0.3553)  time: 0.4593  data: 0.0150  max mem: 7286\n",
      "Epoch: [0]  [ 600/1180]  eta: 0:04:27  lr: 0.000601  loss: 0.7436 (0.6528)  classification: 0.2810 (0.2933)  bbox_regression: 0.4393 (0.3595)  time: 0.4643  data: 0.0180  max mem: 7286\n",
      "Epoch: [0]  [ 700/1180]  eta: 0:03:41  lr: 0.000701  loss: 0.6799 (0.6603)  classification: 0.3057 (0.2970)  bbox_regression: 0.3788 (0.3633)  time: 0.4612  data: 0.0142  max mem: 7286\n",
      "Epoch: [0]  [ 800/1180]  eta: 0:02:54  lr: 0.000801  loss: 0.8129 (0.7033)  classification: 0.4104 (0.3331)  bbox_regression: 0.3838 (0.3702)  time: 0.4582  data: 0.0146  max mem: 7286\n",
      "Epoch: [0]  [ 900/1180]  eta: 0:02:08  lr: 0.000901  loss: 0.5854 (0.7037)  classification: 0.2541 (0.3323)  bbox_regression: 0.3294 (0.3715)  time: 0.4555  data: 0.0129  max mem: 7286\n",
      "Epoch: [0]  [1000/1180]  eta: 0:01:22  lr: 0.001000  loss: 0.6277 (0.7086)  classification: 0.2988 (0.3348)  bbox_regression: 0.3176 (0.3738)  time: 0.4644  data: 0.0149  max mem: 7286\n",
      "Epoch: [0]  [1100/1180]  eta: 0:00:36  lr: 0.001000  loss: 0.5162 (0.7078)  classification: 0.2388 (0.3316)  bbox_regression: 0.3385 (0.3763)  time: 0.4604  data: 0.0153  max mem: 7286\n",
      "Epoch: [0]  [1179/1180]  eta: 0:00:00  lr: 0.001000  loss: 0.5709 (0.7029)  classification: 0.2234 (0.3275)  bbox_regression: 0.3361 (0.3755)  time: 0.4568  data: 0.0144  max mem: 7286\n",
      "Epoch: [0] Total time: 0:09:02 (0.4600 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.6970568878952528\n",
      "0.4796637614120372\n",
      "Epoch Done\n",
      "Epoch: [1]  [   0/1180]  eta: 0:33:45  lr: 0.001000  loss: 0.3465 (0.3465)  classification: 0.1577 (0.1577)  bbox_regression: 0.1888 (0.1888)  time: 1.7166  data: 1.2529  max mem: 7286\n",
      "Epoch: [1]  [ 100/1180]  eta: 0:08:31  lr: 0.001000  loss: 0.6017 (0.6622)  classification: 0.2321 (0.2814)  bbox_regression: 0.3448 (0.3808)  time: 0.4601  data: 0.0144  max mem: 7286\n",
      "Epoch: [1]  [ 200/1180]  eta: 0:07:37  lr: 0.001000  loss: 0.6047 (0.6655)  classification: 0.2191 (0.2816)  bbox_regression: 0.3836 (0.3838)  time: 0.4631  data: 0.0126  max mem: 7286\n",
      "Epoch: [1]  [ 300/1180]  eta: 0:06:48  lr: 0.001000  loss: 0.6329 (0.6866)  classification: 0.3451 (0.2986)  bbox_regression: 0.3738 (0.3880)  time: 0.4570  data: 0.0125  max mem: 7286\n",
      "Epoch: [1]  [ 400/1180]  eta: 0:06:01  lr: 0.001000  loss: 0.5944 (0.6653)  classification: 0.2377 (0.2866)  bbox_regression: 0.3417 (0.3787)  time: 0.4567  data: 0.0117  max mem: 7286\n",
      "Epoch: [1]  [ 500/1180]  eta: 0:05:14  lr: 0.001000  loss: 0.5376 (0.6534)  classification: 0.2100 (0.2803)  bbox_regression: 0.3127 (0.3731)  time: 0.4617  data: 0.0145  max mem: 7286\n",
      "Epoch: [1]  [ 600/1180]  eta: 0:04:28  lr: 0.001000  loss: 0.5406 (0.6521)  classification: 0.2017 (0.2772)  bbox_regression: 0.3522 (0.3749)  time: 0.4585  data: 0.0143  max mem: 7286\n",
      "Epoch: [1]  [ 700/1180]  eta: 0:03:41  lr: 0.001000  loss: 0.6144 (0.6622)  classification: 0.2908 (0.2883)  bbox_regression: 0.3365 (0.3740)  time: 0.4561  data: 0.0119  max mem: 7286\n",
      "Epoch: [1]  [ 800/1180]  eta: 0:02:55  lr: 0.001000  loss: 0.4851 (0.6657)  classification: 0.2230 (0.2919)  bbox_regression: 0.2966 (0.3738)  time: 0.4553  data: 0.0120  max mem: 7286\n",
      "Epoch: [1]  [ 900/1180]  eta: 0:02:08  lr: 0.001000  loss: 0.4610 (0.6591)  classification: 0.1934 (0.2882)  bbox_regression: 0.3066 (0.3710)  time: 0.4592  data: 0.0155  max mem: 7286\n",
      "Epoch: [1]  [1000/1180]  eta: 0:01:22  lr: 0.001000  loss: 0.5045 (0.6529)  classification: 0.2350 (0.2858)  bbox_regression: 0.2738 (0.3671)  time: 0.4582  data: 0.0141  max mem: 7286\n",
      "Epoch: [1]  [1100/1180]  eta: 0:00:36  lr: 0.001000  loss: 0.4892 (0.6540)  classification: 0.2288 (0.2859)  bbox_regression: 0.2967 (0.3681)  time: 0.4577  data: 0.0146  max mem: 7286\n",
      "Epoch: [1]  [1179/1180]  eta: 0:00:00  lr: 0.001000  loss: 0.4779 (0.6505)  classification: 0.1772 (0.2833)  bbox_regression: 0.2786 (0.3672)  time: 0.4568  data: 0.0112  max mem: 7286\n",
      "Epoch: [1] Total time: 0:09:02 (0.4599 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.8080363327469212\n",
      "0.6824243190002692\n",
      "Epoch Done\n",
      "Epoch: [2]  [   0/1180]  eta: 0:28:14  lr: 0.001000  loss: 0.9682 (0.9682)  classification: 0.3148 (0.3148)  bbox_regression: 0.6534 (0.6534)  time: 1.4357  data: 0.9837  max mem: 7286\n",
      "Epoch: [2]  [ 100/1180]  eta: 0:08:28  lr: 0.001000  loss: 0.4776 (0.6122)  classification: 0.2043 (0.2459)  bbox_regression: 0.2991 (0.3663)  time: 0.4598  data: 0.0132  max mem: 7286\n",
      "Epoch: [2]  [ 200/1180]  eta: 0:07:36  lr: 0.001000  loss: 0.6553 (0.5798)  classification: 0.2298 (0.2352)  bbox_regression: 0.3990 (0.3447)  time: 0.4624  data: 0.0142  max mem: 7286\n",
      "Epoch: [2]  [ 300/1180]  eta: 0:06:47  lr: 0.001000  loss: 0.5640 (0.5799)  classification: 0.2210 (0.2372)  bbox_regression: 0.3033 (0.3427)  time: 0.4584  data: 0.0131  max mem: 7286\n",
      "Epoch: [2]  [ 400/1180]  eta: 0:06:00  lr: 0.001000  loss: 0.5473 (0.5869)  classification: 0.2242 (0.2422)  bbox_regression: 0.3064 (0.3447)  time: 0.4587  data: 0.0150  max mem: 7286\n",
      "Epoch: [2]  [ 500/1180]  eta: 0:05:14  lr: 0.001000  loss: 0.5315 (0.5827)  classification: 0.2215 (0.2422)  bbox_regression: 0.2912 (0.3405)  time: 0.4592  data: 0.0152  max mem: 7286\n",
      "Epoch: [2]  [ 600/1180]  eta: 0:04:27  lr: 0.001000  loss: 0.4613 (0.5770)  classification: 0.1808 (0.2384)  bbox_regression: 0.2991 (0.3385)  time: 0.4570  data: 0.0134  max mem: 7286\n",
      "Epoch: [2]  [ 700/1180]  eta: 0:03:41  lr: 0.001000  loss: 0.4331 (0.5752)  classification: 0.1565 (0.2377)  bbox_regression: 0.2781 (0.3375)  time: 0.4572  data: 0.0131  max mem: 7286\n",
      "Epoch: [2]  [ 800/1180]  eta: 0:02:54  lr: 0.001000  loss: 0.4503 (0.5665)  classification: 0.1587 (0.2326)  bbox_regression: 0.2509 (0.3339)  time: 0.4543  data: 0.0122  max mem: 7286\n",
      "Epoch: [2]  [ 900/1180]  eta: 0:02:08  lr: 0.001000  loss: 0.4067 (0.5603)  classification: 0.1503 (0.2285)  bbox_regression: 0.2405 (0.3317)  time: 0.4542  data: 0.0116  max mem: 7286\n",
      "Epoch: [2]  [1000/1180]  eta: 0:01:22  lr: 0.001000  loss: 0.4118 (0.5597)  classification: 0.1594 (0.2277)  bbox_regression: 0.2509 (0.3321)  time: 0.4583  data: 0.0148  max mem: 7286\n",
      "Epoch: [2]  [1100/1180]  eta: 0:00:36  lr: 0.001000  loss: 0.4585 (0.5657)  classification: 0.1654 (0.2345)  bbox_regression: 0.2649 (0.3311)  time: 0.4683  data: 0.0175  max mem: 7286\n",
      "Epoch: [2]  [1179/1180]  eta: 0:00:00  lr: 0.001000  loss: 0.4713 (0.5651)  classification: 0.1725 (0.2341)  bbox_regression: 0.3238 (0.3311)  time: 0.4542  data: 0.0118  max mem: 7286\n",
      "Epoch: [2] Total time: 0:09:02 (0.4601 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.7595355260316357\n",
      "0.580981208264715\n",
      "Epoch Done\n",
      "Epoch: [3]  [   0/1180]  eta: 0:27:44  lr: 0.001000  loss: 0.4400 (0.4400)  classification: 0.1096 (0.1096)  bbox_regression: 0.3304 (0.3304)  time: 1.4102  data: 0.9445  max mem: 7286\n",
      "Epoch: [3]  [ 100/1180]  eta: 0:08:30  lr: 0.001000  loss: 0.4818 (0.5127)  classification: 0.1971 (0.2037)  bbox_regression: 0.2906 (0.3090)  time: 0.4621  data: 0.0167  max mem: 7286\n",
      "Epoch: [3]  [ 200/1180]  eta: 0:07:37  lr: 0.001000  loss: 0.5048 (0.5115)  classification: 0.1570 (0.2022)  bbox_regression: 0.3076 (0.3094)  time: 0.4624  data: 0.0130  max mem: 7286\n",
      "Epoch: [3]  [ 300/1180]  eta: 0:06:48  lr: 0.001000  loss: 0.4863 (0.5068)  classification: 0.1588 (0.2009)  bbox_regression: 0.2907 (0.3059)  time: 0.4587  data: 0.0158  max mem: 7286\n",
      "Epoch: [3]  [ 400/1180]  eta: 0:06:01  lr: 0.001000  loss: 0.6801 (0.5175)  classification: 0.2845 (0.2082)  bbox_regression: 0.3530 (0.3093)  time: 0.4622  data: 0.0153  max mem: 7286\n",
      "Epoch: [3]  [ 500/1180]  eta: 0:05:14  lr: 0.001000  loss: 0.5299 (0.5176)  classification: 0.2130 (0.2113)  bbox_regression: 0.3071 (0.3064)  time: 0.4575  data: 0.0131  max mem: 7286\n",
      "Epoch: [3]  [ 600/1180]  eta: 0:04:27  lr: 0.001000  loss: 0.4173 (0.5197)  classification: 0.1457 (0.2104)  bbox_regression: 0.2749 (0.3093)  time: 0.4581  data: 0.0133  max mem: 7286\n",
      "Epoch: [3]  [ 700/1180]  eta: 0:03:41  lr: 0.001000  loss: 0.5405 (0.5151)  classification: 0.1617 (0.2059)  bbox_regression: 0.3606 (0.3092)  time: 0.4614  data: 0.0168  max mem: 7286\n",
      "Epoch: [3]  [ 800/1180]  eta: 0:02:55  lr: 0.001000  loss: 0.3845 (0.5139)  classification: 0.1377 (0.2032)  bbox_regression: 0.2295 (0.3107)  time: 0.4603  data: 0.0162  max mem: 7286\n",
      "Epoch: [3]  [ 900/1180]  eta: 0:02:08  lr: 0.001000  loss: 0.4856 (0.5208)  classification: 0.1783 (0.2113)  bbox_regression: 0.2827 (0.3094)  time: 0.4595  data: 0.0133  max mem: 7286\n",
      "Epoch: [3]  [1000/1180]  eta: 0:01:22  lr: 0.001000  loss: 0.3658 (0.5173)  classification: 0.1316 (0.2081)  bbox_regression: 0.2536 (0.3092)  time: 0.4601  data: 0.0139  max mem: 7286\n",
      "Epoch: [3]  [1100/1180]  eta: 0:00:36  lr: 0.001000  loss: 0.3850 (0.5164)  classification: 0.1543 (0.2074)  bbox_regression: 0.2312 (0.3090)  time: 0.4563  data: 0.0112  max mem: 7286\n",
      "Epoch: [3]  [1179/1180]  eta: 0:00:00  lr: 0.001000  loss: 0.4748 (0.5170)  classification: 0.2166 (0.2076)  bbox_regression: 0.2685 (0.3093)  time: 0.4529  data: 0.0109  max mem: 7286\n",
      "Epoch: [3] Total time: 0:09:03 (0.4604 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.8386675071554894\n",
      "0.6680075110001408\n",
      "Epoch Done\n",
      "Epoch: [4]  [   0/1180]  eta: 0:26:38  lr: 0.000100  loss: 0.3271 (0.3271)  classification: 0.1556 (0.1556)  bbox_regression: 0.1714 (0.1714)  time: 1.3544  data: 0.9026  max mem: 7286\n",
      "Epoch: [4]  [ 100/1180]  eta: 0:08:23  lr: 0.000100  loss: 0.3161 (0.4642)  classification: 0.1469 (0.1922)  bbox_regression: 0.1904 (0.2719)  time: 0.4574  data: 0.0115  max mem: 7286\n",
      "Epoch: [4]  [ 200/1180]  eta: 0:07:33  lr: 0.000100  loss: 0.4016 (0.4563)  classification: 0.1476 (0.1834)  bbox_regression: 0.2676 (0.2729)  time: 0.4565  data: 0.0118  max mem: 7286\n",
      "Epoch: [4]  [ 300/1180]  eta: 0:06:45  lr: 0.000100  loss: 0.3905 (0.4470)  classification: 0.1681 (0.1774)  bbox_regression: 0.1741 (0.2696)  time: 0.4592  data: 0.0136  max mem: 7286\n",
      "Epoch: [4]  [ 400/1180]  eta: 0:05:59  lr: 0.000100  loss: 0.3104 (0.4332)  classification: 0.1316 (0.1697)  bbox_regression: 0.1960 (0.2635)  time: 0.4641  data: 0.0164  max mem: 7286\n",
      "Epoch: [4]  [ 500/1180]  eta: 0:05:12  lr: 0.000100  loss: 0.3957 (0.4254)  classification: 0.1289 (0.1670)  bbox_regression: 0.2565 (0.2585)  time: 0.4587  data: 0.0129  max mem: 7286\n",
      "Epoch: [4]  [ 600/1180]  eta: 0:04:26  lr: 0.000100  loss: 0.3309 (0.4246)  classification: 0.1101 (0.1662)  bbox_regression: 0.2170 (0.2584)  time: 0.4591  data: 0.0155  max mem: 7286\n",
      "Epoch: [4]  [ 700/1180]  eta: 0:03:40  lr: 0.000100  loss: 0.3635 (0.4214)  classification: 0.1080 (0.1642)  bbox_regression: 0.2390 (0.2571)  time: 0.4617  data: 0.0161  max mem: 7286\n",
      "Epoch: [4]  [ 800/1180]  eta: 0:02:54  lr: 0.000100  loss: 0.3717 (0.4137)  classification: 0.1177 (0.1599)  bbox_regression: 0.2404 (0.2538)  time: 0.4582  data: 0.0129  max mem: 7286\n",
      "Epoch: [4]  [ 900/1180]  eta: 0:02:08  lr: 0.000100  loss: 0.3557 (0.4135)  classification: 0.1185 (0.1599)  bbox_regression: 0.2348 (0.2536)  time: 0.4568  data: 0.0135  max mem: 7286\n",
      "Epoch: [4]  [1000/1180]  eta: 0:01:22  lr: 0.000100  loss: 0.3428 (0.4090)  classification: 0.1173 (0.1583)  bbox_regression: 0.1839 (0.2507)  time: 0.4572  data: 0.0118  max mem: 7286\n",
      "Epoch: [4]  [1100/1180]  eta: 0:00:36  lr: 0.000100  loss: 0.3059 (0.4078)  classification: 0.1191 (0.1577)  bbox_regression: 0.1656 (0.2502)  time: 0.4551  data: 0.0126  max mem: 7286\n",
      "Epoch: [4]  [1179/1180]  eta: 0:00:00  lr: 0.000100  loss: 0.3627 (0.4081)  classification: 0.1288 (0.1578)  bbox_regression: 0.2299 (0.2504)  time: 0.4531  data: 0.0108  max mem: 7286\n",
      "Epoch: [4] Total time: 0:09:02 (0.4596 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.8847638137191961\n",
      "0.8081132405072229\n",
      "Epoch Done\n",
      "Epoch: [5]  [   0/1180]  eta: 0:36:28  lr: 0.000100  loss: 0.5102 (0.5102)  classification: 0.2437 (0.2437)  bbox_regression: 0.2665 (0.2665)  time: 1.8543  data: 1.3985  max mem: 7286\n",
      "Epoch: [5]  [ 100/1180]  eta: 0:08:30  lr: 0.000100  loss: 0.3038 (0.3771)  classification: 0.1152 (0.1435)  bbox_regression: 0.2088 (0.2335)  time: 0.4574  data: 0.0133  max mem: 7286\n",
      "Epoch: [5]  [ 200/1180]  eta: 0:07:36  lr: 0.000100  loss: 0.3361 (0.3788)  classification: 0.1275 (0.1402)  bbox_regression: 0.2344 (0.2386)  time: 0.4597  data: 0.0160  max mem: 7286\n",
      "Epoch: [5]  [ 300/1180]  eta: 0:06:47  lr: 0.000100  loss: 0.3220 (0.3677)  classification: 0.1081 (0.1334)  bbox_regression: 0.2077 (0.2343)  time: 0.4593  data: 0.0143  max mem: 7286\n",
      "Epoch: [5]  [ 400/1180]  eta: 0:06:00  lr: 0.000100  loss: 0.2721 (0.3714)  classification: 0.0756 (0.1370)  bbox_regression: 0.1677 (0.2344)  time: 0.4576  data: 0.0111  max mem: 7286\n",
      "Epoch: [5]  [ 500/1180]  eta: 0:05:14  lr: 0.000100  loss: 0.3026 (0.3701)  classification: 0.1006 (0.1383)  bbox_regression: 0.2009 (0.2318)  time: 0.4626  data: 0.0162  max mem: 7286\n",
      "Epoch: [5]  [ 600/1180]  eta: 0:04:27  lr: 0.000100  loss: 0.3468 (0.3755)  classification: 0.1173 (0.1399)  bbox_regression: 0.2358 (0.2355)  time: 0.4588  data: 0.0120  max mem: 7286\n",
      "Epoch: [5]  [ 700/1180]  eta: 0:03:41  lr: 0.000100  loss: 0.3413 (0.3772)  classification: 0.1271 (0.1417)  bbox_regression: 0.2085 (0.2355)  time: 0.4564  data: 0.0123  max mem: 7286\n",
      "Epoch: [5]  [ 800/1180]  eta: 0:02:55  lr: 0.000100  loss: 0.3096 (0.3761)  classification: 0.1123 (0.1414)  bbox_regression: 0.2020 (0.2347)  time: 0.4577  data: 0.0133  max mem: 7286\n",
      "Epoch: [5]  [ 900/1180]  eta: 0:02:08  lr: 0.000100  loss: 0.2984 (0.3702)  classification: 0.1112 (0.1398)  bbox_regression: 0.1617 (0.2304)  time: 0.4604  data: 0.0132  max mem: 7286\n",
      "Epoch: [5]  [1000/1180]  eta: 0:01:22  lr: 0.000100  loss: 0.3178 (0.3715)  classification: 0.1050 (0.1401)  bbox_regression: 0.2048 (0.2314)  time: 0.4579  data: 0.0123  max mem: 7286\n",
      "Epoch: [5]  [1100/1180]  eta: 0:00:36  lr: 0.000100  loss: 0.3181 (0.3733)  classification: 0.1054 (0.1403)  bbox_regression: 0.2044 (0.2329)  time: 0.4581  data: 0.0132  max mem: 7286\n",
      "Epoch: [5]  [1179/1180]  eta: 0:00:00  lr: 0.000100  loss: 0.3075 (0.3725)  classification: 0.0964 (0.1400)  bbox_regression: 0.2123 (0.2325)  time: 0.4539  data: 0.0123  max mem: 7286\n",
      "Epoch: [5] Total time: 0:09:03 (0.4602 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.8954172931230491\n",
      "0.8195283573916549\n",
      "Epoch Done\n",
      "Epoch: [6]  [   0/1180]  eta: 0:28:28  lr: 0.000100  loss: 0.4081 (0.4081)  classification: 0.1705 (0.1705)  bbox_regression: 0.2376 (0.2376)  time: 1.4477  data: 0.9970  max mem: 7286\n",
      "Epoch: [6]  [ 100/1180]  eta: 0:08:30  lr: 0.000100  loss: 0.3197 (0.3865)  classification: 0.0939 (0.1422)  bbox_regression: 0.2093 (0.2444)  time: 0.4613  data: 0.0157  max mem: 7286\n",
      "Epoch: [6]  [ 200/1180]  eta: 0:07:36  lr: 0.000100  loss: 0.2392 (0.3459)  classification: 0.0923 (0.1267)  bbox_regression: 0.1703 (0.2192)  time: 0.4609  data: 0.0167  max mem: 7286\n",
      "Epoch: [6]  [ 300/1180]  eta: 0:06:47  lr: 0.000100  loss: 0.2729 (0.3425)  classification: 0.1083 (0.1244)  bbox_regression: 0.1833 (0.2181)  time: 0.4562  data: 0.0129  max mem: 7286\n",
      "Epoch: [6]  [ 400/1180]  eta: 0:06:00  lr: 0.000100  loss: 0.2684 (0.3438)  classification: 0.0903 (0.1256)  bbox_regression: 0.2084 (0.2182)  time: 0.4589  data: 0.0143  max mem: 7286\n",
      "Epoch: [6]  [ 500/1180]  eta: 0:05:14  lr: 0.000100  loss: 0.2514 (0.3446)  classification: 0.1062 (0.1266)  bbox_regression: 0.1519 (0.2180)  time: 0.4635  data: 0.0153  max mem: 7286\n",
      "Epoch: [6]  [ 600/1180]  eta: 0:04:27  lr: 0.000100  loss: 0.2981 (0.3487)  classification: 0.1096 (0.1289)  bbox_regression: 0.1863 (0.2198)  time: 0.4624  data: 0.0161  max mem: 7286\n",
      "Epoch: [6]  [ 700/1180]  eta: 0:03:41  lr: 0.000100  loss: 0.3285 (0.3507)  classification: 0.1173 (0.1305)  bbox_regression: 0.2299 (0.2202)  time: 0.4616  data: 0.0155  max mem: 7286\n",
      "Epoch: [6]  [ 800/1180]  eta: 0:02:55  lr: 0.000100  loss: 0.2854 (0.3486)  classification: 0.1055 (0.1297)  bbox_regression: 0.1768 (0.2189)  time: 0.4588  data: 0.0127  max mem: 7286\n",
      "Epoch: [6]  [ 900/1180]  eta: 0:02:09  lr: 0.000100  loss: 0.3038 (0.3533)  classification: 0.1074 (0.1319)  bbox_regression: 0.1961 (0.2214)  time: 0.4602  data: 0.0156  max mem: 7286\n",
      "Epoch: [6]  [1000/1180]  eta: 0:01:23  lr: 0.000100  loss: 0.3230 (0.3577)  classification: 0.1077 (0.1336)  bbox_regression: 0.2189 (0.2241)  time: 0.4607  data: 0.0133  max mem: 7286\n",
      "Epoch: [6]  [1100/1180]  eta: 0:00:36  lr: 0.000100  loss: 0.2681 (0.3566)  classification: 0.0798 (0.1326)  bbox_regression: 0.1883 (0.2240)  time: 0.4624  data: 0.0184  max mem: 7286\n",
      "Epoch: [6]  [1179/1180]  eta: 0:00:00  lr: 0.000100  loss: 0.2957 (0.3561)  classification: 0.1139 (0.1325)  bbox_regression: 0.1895 (0.2236)  time: 0.4596  data: 0.0130  max mem: 7286\n",
      "Epoch: [6] Total time: 0:09:04 (0.4612 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.8932238778837192\n",
      "0.8169760737981601\n",
      "Epoch Done\n",
      "Epoch: [7]  [   0/1180]  eta: 0:32:24  lr: 0.000100  loss: 0.3535 (0.3535)  classification: 0.0859 (0.0859)  bbox_regression: 0.2675 (0.2675)  time: 1.6480  data: 1.1923  max mem: 7286\n",
      "Epoch: [7]  [ 100/1180]  eta: 0:08:30  lr: 0.000100  loss: 0.2777 (0.3406)  classification: 0.0931 (0.1299)  bbox_regression: 0.1901 (0.2107)  time: 0.4622  data: 0.0132  max mem: 7286\n",
      "Epoch: [7]  [ 200/1180]  eta: 0:07:37  lr: 0.000100  loss: 0.2996 (0.3259)  classification: 0.1038 (0.1200)  bbox_regression: 0.1727 (0.2060)  time: 0.4690  data: 0.0175  max mem: 7286\n",
      "Epoch: [7]  [ 300/1180]  eta: 0:06:48  lr: 0.000100  loss: 0.2388 (0.3247)  classification: 0.1076 (0.1212)  bbox_regression: 0.1563 (0.2035)  time: 0.4579  data: 0.0123  max mem: 7286\n",
      "Epoch: [7]  [ 400/1180]  eta: 0:06:01  lr: 0.000100  loss: 0.3520 (0.3301)  classification: 0.0983 (0.1208)  bbox_regression: 0.2262 (0.2093)  time: 0.4681  data: 0.0176  max mem: 7286\n",
      "Epoch: [7]  [ 500/1180]  eta: 0:05:14  lr: 0.000100  loss: 0.3094 (0.3347)  classification: 0.1194 (0.1241)  bbox_regression: 0.1717 (0.2106)  time: 0.4576  data: 0.0130  max mem: 7286\n",
      "Epoch: [7]  [ 600/1180]  eta: 0:04:27  lr: 0.000100  loss: 0.2591 (0.3355)  classification: 0.0999 (0.1244)  bbox_regression: 0.1825 (0.2111)  time: 0.4611  data: 0.0151  max mem: 7286\n",
      "Epoch: [7]  [ 700/1180]  eta: 0:03:41  lr: 0.000100  loss: 0.3005 (0.3384)  classification: 0.1036 (0.1261)  bbox_regression: 0.1823 (0.2124)  time: 0.4607  data: 0.0158  max mem: 7286\n",
      "Epoch: [7]  [ 800/1180]  eta: 0:02:55  lr: 0.000100  loss: 0.3446 (0.3393)  classification: 0.1075 (0.1258)  bbox_regression: 0.2031 (0.2135)  time: 0.4635  data: 0.0174  max mem: 7286\n",
      "Epoch: [7]  [ 900/1180]  eta: 0:02:09  lr: 0.000100  loss: 0.3313 (0.3412)  classification: 0.1014 (0.1261)  bbox_regression: 0.1972 (0.2151)  time: 0.4615  data: 0.0152  max mem: 7286\n",
      "Epoch: [7]  [1000/1180]  eta: 0:01:23  lr: 0.000100  loss: 0.2997 (0.3418)  classification: 0.0987 (0.1263)  bbox_regression: 0.1972 (0.2155)  time: 0.4607  data: 0.0126  max mem: 7286\n",
      "Epoch: [7]  [1100/1180]  eta: 0:00:36  lr: 0.000100  loss: 0.2583 (0.3399)  classification: 0.0920 (0.1251)  bbox_regression: 0.1663 (0.2147)  time: 0.4720  data: 0.0198  max mem: 7286\n",
      "Epoch: [7]  [1179/1180]  eta: 0:00:00  lr: 0.000100  loss: 0.3211 (0.3407)  classification: 0.1284 (0.1256)  bbox_regression: 0.1957 (0.2150)  time: 0.4559  data: 0.0133  max mem: 7286\n",
      "Epoch: [7] Total time: 0:09:04 (0.4614 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.887384271478803\n",
      "0.8029943716548411\n",
      "Epoch Done\n",
      "Epoch: [8]  [   0/1180]  eta: 0:43:05  lr: 0.000010  loss: 0.2131 (0.2131)  classification: 0.1463 (0.1463)  bbox_regression: 0.0668 (0.0668)  time: 2.1914  data: 1.7498  max mem: 7286\n",
      "Epoch: [8]  [ 100/1180]  eta: 0:08:35  lr: 0.000010  loss: 0.3148 (0.3375)  classification: 0.1237 (0.1258)  bbox_regression: 0.1941 (0.2116)  time: 0.4585  data: 0.0124  max mem: 7286\n",
      "Epoch: [8]  [ 200/1180]  eta: 0:07:39  lr: 0.000010  loss: 0.2164 (0.3183)  classification: 0.0697 (0.1157)  bbox_regression: 0.1582 (0.2026)  time: 0.4600  data: 0.0147  max mem: 7286\n",
      "Epoch: [8]  [ 300/1180]  eta: 0:06:49  lr: 0.000010  loss: 0.2766 (0.3186)  classification: 0.0959 (0.1164)  bbox_regression: 0.1808 (0.2023)  time: 0.4577  data: 0.0125  max mem: 7286\n",
      "Epoch: [8]  [ 400/1180]  eta: 0:06:01  lr: 0.000010  loss: 0.3085 (0.3221)  classification: 0.0800 (0.1178)  bbox_regression: 0.2191 (0.2043)  time: 0.4615  data: 0.0133  max mem: 7286\n",
      "Epoch: [8]  [ 500/1180]  eta: 0:05:15  lr: 0.000010  loss: 0.2758 (0.3178)  classification: 0.1020 (0.1171)  bbox_regression: 0.1613 (0.2007)  time: 0.4568  data: 0.0128  max mem: 7286\n",
      "Epoch: [8]  [ 600/1180]  eta: 0:04:28  lr: 0.000010  loss: 0.2647 (0.3169)  classification: 0.0828 (0.1164)  bbox_regression: 0.1738 (0.2005)  time: 0.4612  data: 0.0145  max mem: 7286\n",
      "Epoch: [8]  [ 700/1180]  eta: 0:03:42  lr: 0.000010  loss: 0.3202 (0.3176)  classification: 0.0906 (0.1166)  bbox_regression: 0.2264 (0.2010)  time: 0.4592  data: 0.0134  max mem: 7286\n",
      "Epoch: [8]  [ 800/1180]  eta: 0:02:55  lr: 0.000010  loss: 0.3297 (0.3162)  classification: 0.0838 (0.1157)  bbox_regression: 0.2117 (0.2005)  time: 0.4586  data: 0.0147  max mem: 7286\n",
      "Epoch: [8]  [ 900/1180]  eta: 0:02:09  lr: 0.000010  loss: 0.2194 (0.3170)  classification: 0.0830 (0.1155)  bbox_regression: 0.1706 (0.2015)  time: 0.4578  data: 0.0113  max mem: 7286\n",
      "Epoch: [8]  [1000/1180]  eta: 0:01:23  lr: 0.000010  loss: 0.2790 (0.3184)  classification: 0.0973 (0.1161)  bbox_regression: 0.1680 (0.2023)  time: 0.4556  data: 0.0121  max mem: 7286\n",
      "Epoch: [8]  [1100/1180]  eta: 0:00:36  lr: 0.000010  loss: 0.2226 (0.3203)  classification: 0.0827 (0.1169)  bbox_regression: 0.1672 (0.2034)  time: 0.4601  data: 0.0138  max mem: 7286\n",
      "Epoch: [8]  [1179/1180]  eta: 0:00:00  lr: 0.000010  loss: 0.2993 (0.3238)  classification: 0.1074 (0.1189)  bbox_regression: 0.1752 (0.2049)  time: 0.4582  data: 0.0153  max mem: 7286\n",
      "Epoch: [8] Total time: 0:09:04 (0.4613 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.8985133644861092\n",
      "0.818148155672517\n",
      "Epoch Done\n",
      "Epoch: [9]  [   0/1180]  eta: 0:34:45  lr: 0.000010  loss: 0.1829 (0.1829)  classification: 0.0734 (0.0734)  bbox_regression: 0.1095 (0.1095)  time: 1.7675  data: 1.3247  max mem: 7286\n",
      "Epoch: [9]  [ 100/1180]  eta: 0:08:31  lr: 0.000010  loss: 0.2743 (0.3151)  classification: 0.0920 (0.1190)  bbox_regression: 0.1818 (0.1961)  time: 0.4570  data: 0.0133  max mem: 7286\n",
      "Epoch: [9]  [ 200/1180]  eta: 0:07:37  lr: 0.000010  loss: 0.2987 (0.3190)  classification: 0.1154 (0.1194)  bbox_regression: 0.2034 (0.1996)  time: 0.4628  data: 0.0157  max mem: 7286\n",
      "Epoch: [9]  [ 300/1180]  eta: 0:06:48  lr: 0.000010  loss: 0.2604 (0.3107)  classification: 0.0845 (0.1147)  bbox_regression: 0.1694 (0.1960)  time: 0.4630  data: 0.0131  max mem: 7286\n",
      "Epoch: [9]  [ 400/1180]  eta: 0:06:01  lr: 0.000010  loss: 0.2855 (0.3117)  classification: 0.0921 (0.1130)  bbox_regression: 0.1852 (0.1987)  time: 0.4594  data: 0.0142  max mem: 7286\n",
      "Epoch: [9]  [ 500/1180]  eta: 0:05:15  lr: 0.000010  loss: 0.2525 (0.3134)  classification: 0.0891 (0.1139)  bbox_regression: 0.1283 (0.1995)  time: 0.4632  data: 0.0141  max mem: 7286\n",
      "Epoch: [9]  [ 600/1180]  eta: 0:04:28  lr: 0.000010  loss: 0.2989 (0.3189)  classification: 0.0777 (0.1169)  bbox_regression: 0.1717 (0.2020)  time: 0.4578  data: 0.0114  max mem: 7286\n",
      "Epoch: [9]  [ 700/1180]  eta: 0:03:41  lr: 0.000010  loss: 0.3308 (0.3236)  classification: 0.1259 (0.1193)  bbox_regression: 0.2275 (0.2042)  time: 0.4678  data: 0.0190  max mem: 7286\n",
      "Epoch: [9]  [ 800/1180]  eta: 0:02:55  lr: 0.000010  loss: 0.2865 (0.3236)  classification: 0.1149 (0.1195)  bbox_regression: 0.1785 (0.2041)  time: 0.4609  data: 0.0133  max mem: 7286\n",
      "Epoch: [9]  [ 900/1180]  eta: 0:02:09  lr: 0.000010  loss: 0.3305 (0.3243)  classification: 0.1241 (0.1198)  bbox_regression: 0.1760 (0.2045)  time: 0.4560  data: 0.0130  max mem: 7286\n",
      "Epoch: [9]  [1000/1180]  eta: 0:01:23  lr: 0.000010  loss: 0.2270 (0.3235)  classification: 0.0580 (0.1192)  bbox_regression: 0.1460 (0.2042)  time: 0.4592  data: 0.0133  max mem: 7286\n",
      "Epoch: [9]  [1100/1180]  eta: 0:00:36  lr: 0.000010  loss: 0.2229 (0.3216)  classification: 0.0812 (0.1185)  bbox_regression: 0.1424 (0.2031)  time: 0.4640  data: 0.0147  max mem: 7286\n",
      "Epoch: [9]  [1179/1180]  eta: 0:00:00  lr: 0.000010  loss: 0.3589 (0.3223)  classification: 0.0884 (0.1190)  bbox_regression: 0.2410 (0.2033)  time: 0.4552  data: 0.0116  max mem: 7286\n",
      "Epoch: [9] Total time: 0:09:05 (0.4619 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.8955906069682928\n",
      "0.8238858110594021\n",
      "Epoch Done\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "del model\n",
    "del optimizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=False, num_classes=2, pretrained_backbone=True, \n",
    "                                                           min_size=params['target_size'][0], max_size = params['target_size'][1],\n",
    "                                                           trainable_backbone_layers = 5)\n",
    "model.load_state_dict(torch.load('/app/host/lacmus/weights/resnet50_LADD_head.pth'), strict=True)\n",
    "\n",
    "# the computation device\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=params['lr'], momentum=0.9, weight_decay=0.0005) \n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=4,\n",
    "                                               gamma=0.1)\n",
    "\n",
    "for epoch in range(10): # train with backbone now\n",
    "\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=100)\n",
    "    print (\"Train done, evaluating.\")\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    inference_res = evaluate(model,data_loader_val)\n",
    "    print('Inference done, computing mAp : ')\n",
    "    print(evaluate_res(inference_res, iou_threshold = 0.5, score_threshold = 0.05))    \n",
    "    print(evaluate_res(inference_res, iou_threshold = 0.6, score_threshold = 0.05))\n",
    "    print('Epoch Done')\n",
    "    torch.save(model.state_dict(), '/app/host/lacmus/weights/resnet50_LADD_epoch_%i.pth'%epoch)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e6d0f-88e9-4b3c-8b1e-f0095ea87e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to test evaluation model and show detections\n",
    "\n",
    "dataset_test = LADDDataSET(voc_root,'test',get_transform(train=False,target_size=params['target_size'])) \n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_val, batch_size=1, shuffle=False, num_workers=1\n",
    "     ,collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "image_idx = 0\n",
    "\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "model.eval()\n",
    "for images, targets in data_loader_test:\n",
    "    g_images = list(img.to(device) for img in images)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    outputs = model(g_images)\n",
    "\n",
    "    outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "    res = targets, outputs\n",
    "    break\n",
    "\n",
    "\n",
    "im = F.to_pil_image(images[image_idx])\n",
    "targets\n",
    "# im = to_pil_image(dataset[10][0])\n",
    "draw = ImageDraw.Draw(im)\n",
    "\n",
    "for idx in range(len(outputs[image_idx]['boxes'])):\n",
    "    width = math.ceil(outputs[image_idx]['scores'][idx]*10)\n",
    "    bb = outputs[0]['boxes'][idx]\n",
    "    draw.line([(bb[0], bb[1]), (bb[0], bb[3]), (bb[2], bb[3]),\n",
    "               (bb[2], bb[1]), (bb[0], bb[1])], width=width, fill=(255, 0, 0))\n",
    "\n",
    "for bb in targets[image_idx]['boxes'][:10]:\n",
    "    draw.line([(bb[0], bb[1]), (bb[0], bb[3]), (bb[2], bb[3]),\n",
    "               (bb[2], bb[1]), (bb[0], bb[1])], width=4, fill=(0,255, 0))\n",
    "im.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d10fc-37cf-4e84-9014-a7b0c5c58704",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecf6ed4-b8de-46e6-9af1-3d1f0fd08d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
