{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "669fc8fc-881a-4217-a78b-b834ad4dd070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c2610dd-9ed8-4bac-9247-02d6af68af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'From_Vzhik/DJI_0290.JPG'\n",
    "model_bin ='../git/ladd-and-weights/weights/yolo5/yolo5_fullDS_TF.pb'\n",
    "network_in_size = 1984"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d527292-eb03-4eee-b9c1-bebf49128814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_shape(path: str):\n",
    "    img = cv2.imread(path) ## ??? is it the same way in C#? Quite inefficient\n",
    "    return img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d41acc8-b589-468f-83db-b5c79ea22833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_resize_scale(image_shape):\n",
    "    r = min(network_in_size / image_shape[0], network_in_size / image_shape[1])\n",
    "    r = min(r, 1.0)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "801a72f9-b7f7-48a0-8400-fdd380c2fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_tf(path: str, sess): #RGB\n",
    "    h, w, _ = get_image_shape(path)\n",
    "    scale = compute_resize_scale((h, w))\n",
    "    new_unpad_size = [int(round(h * scale)), int(round(w * scale))] ## round!!!!\n",
    "\n",
    "    file_reader = tf.io.read_file(filename=path, name=\"file_reader\")\n",
    "    decode_jpeg = tf.image.decode_jpeg(file_reader, channels=3, dct_method=\"INTEGER_ACCURATE\",name=\"decode_jpeg\")\n",
    "    divider = tf.constant(255.0, dtype=tf.float32, name=\"divider\")\n",
    "    casted = tf.cast(decode_jpeg, dtype=tf.float32, name=\"cast\")\n",
    "    casted_normalized = tf.divide(casted, divider, name=\"normalized\")\n",
    "\n",
    "    dims_expander = tf.expand_dims(casted_normalized, 0, name=\"dims_expander\")\n",
    "    resize_jpeg = tf.compat.v1.image.resize_bilinear(dims_expander, new_unpad_size, half_pixel_centers=True, align_corners=False, name=\"resize\")\n",
    "    # Below yeilds the same results\n",
    "    # resize_jpeg = tf.image.resize(dims_expander, new_unpad_size, method=tf.image.ResizeMethod.BILINEAR,name=\"resize\")\n",
    "    \n",
    "    dh = (network_in_size - new_unpad_size[0])/2\n",
    "    dw = (network_in_size - new_unpad_size[1])/2\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    pad = [[0, 0], [top,bottom], [left,right] ,[0, 0]]    \n",
    "    image_pad = tf.pad(resize_jpeg, pad, mode = \"CONSTANT\", constant_values = 114.0/255.0, name=\"output\")    \n",
    "    \n",
    "    return image_pad, w, h, top, left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc5c1434-2b53-45d4-8195-b8d4147b5cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_tf(model_bin: str, sess):\n",
    "    with tf.io.gfile.GFile(model_bin, 'rb') as f:\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "        return sess.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef9766c4-7e38-439f-9f44-94ff1cf121c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_tf(image, model, sess):\n",
    "    x = model.get_tensor_by_name('x:0')\n",
    "    boxes = model.get_tensor_by_name('Identity:0')\n",
    "    scores = model.get_tensor_by_name('Identity_1:0')\n",
    "    classes = model.get_tensor_by_name('Identity_2:0')\n",
    "    valid_detections = model.get_tensor_by_name('Identity_3:0')\n",
    "\n",
    "    boxes, scores, classes, valid_detections = sess.run([boxes, scores, classes, valid_detections], feed_dict={\n",
    "            x: image\n",
    "        })\n",
    "    return boxes, scores, classes, valid_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33bc939e-0c5e-4612-9fa8-e72d8ca89aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-22 19:07:50.230980: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-22 19:07:50.231361: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-22 19:07:50.232822: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-01-22 19:07:51.037381: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2022-01-22 19:07:51.067263: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2400000000 Hz\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    image_tf, w, h, top, left = read_image_tf(path,sess)\n",
    "    model = load_model_tf(model_bin, sess)\n",
    "    boxes, scores, _, valid_detections = infer_tf(image_tf.eval(), model, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41b6af74-3302-4b71-b7d5-c620a816ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(x):\n",
    "    return min(max((x),0.0),1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4ea7f27-491e-43da-b975-77ffdd958959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_predictions(boxes, scores, valid_detections, image_w, image_h,top,left):\n",
    "    result = []\n",
    "    for i in range(valid_detections[0]):\n",
    "        x0=boxes[0][i][0]\n",
    "        x1=boxes[0][i][2]\n",
    "        y0=boxes[0][i][1]\n",
    "        y1=boxes[0][i][3]\n",
    "        # Adjust for padding\n",
    "        x0 = clip((x0 - left / network_in_size) / (1 -  2 * left / network_in_size))\n",
    "        x1 = clip((x1 - left / network_in_size) / (1 -  2 * left / network_in_size))\n",
    "        y0 = clip((y0 - top / network_in_size) / (1 -  2 * top / network_in_size))\n",
    "        y1 = clip((y1 - top / network_in_size) / (1 -  2 * top / network_in_size))\n",
    "        # convert to pixels\n",
    "        x0 = round(x0*image_w)\n",
    "        x1 = round(x1*image_w)\n",
    "        y0 = round(y0*image_h)\n",
    "        y1 = round(y1*image_h)\n",
    "        \n",
    "        result.append({\n",
    "            'box':[x0,y0,x1,y1]\n",
    "            })\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30f46a95-9aec-4e35-af55-7f4bb86e25d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = transform_predictions(boxes, scores, valid_detections,w,h, top, left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d894b68-4026-4a32-8e94-c3e484f54f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(path)\n",
    "draw = ImageDraw.Draw(im)\n",
    "\n",
    "for detection in outputs[:10]:\n",
    "    bb = detection['box']\n",
    "    draw.line([(bb[0], bb[1]), (bb[0], bb[3]), (bb[2], bb[3]),\n",
    "               (bb[2], bb[1]), (bb[0], bb[1])], width=4, fill=(255, 0, 0))\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ec93fe-0f31-4404-9017-6228157032aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
