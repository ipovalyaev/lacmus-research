{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf73ca5-02c9-41a5-9a50-2c67a4af0c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models.detection.retinanet import RetinaNet\n",
    "from torchvision.models.detection.faster_rcnn import FasterRCNN\n",
    "import  torchvision.transforms.functional as F\n",
    "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
    "\n",
    "\n",
    "from functions import *\n",
    "from functions_torch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d1984d0-a0d1-4195-8694-4f355361da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['target_size']=(800,1333)\n",
    "params['batch_size'] = 4\n",
    "params['lr'] = 0.005\n",
    "ds_root = '../../ladd-and-weights/dataset/pretrain/sdd-lacmus-version/'\n",
    "weights_root = '../../ladd-and-weights/weights/torch/pretrain/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b63ba9b-2b9f-4073-96b6-2cfdad94eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDDDataSET(torch.utils.data.Dataset):\n",
    "    def __init__(self, typeOfDS, transforms=None):\n",
    "        self.typeOfDS = typeOfDS\n",
    "        self.labels = pd.read_csv(os.path.join(ds_root,'%s_annotations_pedestrian.csv'%typeOfDS), header = None, \n",
    "            names = ['image','x0','y0','x1','y1','class'])\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.image.nunique()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images ad masks\n",
    "        img_name = self.labels.image.unique()[idx]\n",
    "        img_labels = self.labels [self.labels.image == img_name]\n",
    "        img = Image.open(ds_root+img_name).convert(\"RGB\") #convert from tutorial, do we need it?\n",
    "\n",
    "        # get bounding box coordinates \n",
    "        num_objs = img_labels.shape[0]\n",
    "        boxes = []\n",
    "        for l in img_labels.iterrows():\n",
    "            boxes.append([l[1]['x0'], l[1]['y0'], l[1]['x1'], l[1]['y1']])\n",
    "\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)         # there is only one class\n",
    "        target[\"labels\"] = labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72369d23-c361-414b-8557-1deec22bdbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to test dataset implementation\n",
    "# im_idx = 10\n",
    "\n",
    "# dataset = SDDDataSET('test',get_transform(train=True)) \n",
    "# (image,target) = dataset[im_idx] \n",
    "# im = F.to_pil_image(image)\n",
    "# draw = ImageDraw.Draw(im)\n",
    "\n",
    "# for bb in target['boxes']:\n",
    "#     draw.line([(bb[0], bb[1]), (bb[0], bb[3]), (bb[2], bb[3]),\n",
    "#                (bb[2], bb[1]), (bb[0], bb[1])], width=4, fill=(255, 0, 0))\n",
    "\n",
    "# im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc868c76-562f-40aa-9d75-441cc9912d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = SDDDataSET('train', get_transform(train=True,target_size=params['target_size']))\n",
    "dataset_val = SDDDataSET('val', get_transform(train=False,target_size=params['target_size']))\n",
    "\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=params['batch_size'], shuffle=True, num_workers=4\n",
    "     ,collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "    dataset_val, batch_size=1, shuffle=False, num_workers=4\n",
    "     ,collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4891861-a61f-4c64-883d-021ccd279dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Docstring (don't work)\n",
    "# anchor_generator = AnchorGenerator(\n",
    "#             sizes=((16, 32, 64, 128, 256),),\n",
    "#             aspect_ratios=((0.25, 0.5, 1.0, 2.0, 4.0),), \n",
    "#          )\n",
    "\n",
    "# # Retina anchors\n",
    "# [anchor_parameters]\n",
    "# sizes   = 16 32 64 128 256\n",
    "# strides = 8 16 32 64 128\n",
    "# ratios  = 0.5 1 2 3\n",
    "# scales  = 1 1.2 1.6  # approx equal to 2**(1.0/3)=1.26 and 2**(2.0/3)=1.59\n",
    "\n",
    "anchor_sizes = tuple((x, int(x * 2 ** (1.0 / 3)), int(x * 2 ** (2.0 / 3))) for x in [16, 32, 64, 128, 256])\n",
    "aspect_ratios = ((0.5, 1.0, 2.0, 3.0),) * len(anchor_sizes)\n",
    "anchor_generator = AnchorGenerator(\n",
    "    anchor_sizes, aspect_ratios\n",
    ")\n",
    "# # load an instance segmentation model pre-trained on COCO    \n",
    "model = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=False, num_classes=2, pretrained_backbone=True,\n",
    "                                                            min_size=params['target_size'][0], max_size = params['target_size'][1],\n",
    "                                                           anchor_generator=anchor_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77125a41-f1fc-4d5e-8e3f-a9158373cfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load an instance segmentation model pre-trained on COCO    \n",
    "\n",
    "# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, num_classes=2, pretrained_backbone=True,\n",
    "#                                                             min_size=params['target_size'][0], max_size = params['target_size'][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d779973-b8b7-4916-9ab9-e28793a5a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the computation device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=params['lr'], momentum=0.9, weight_decay=0.0005) #lr 0.001 -> 0.005\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0deefc4c-87ff-46e6-9bd3-ae7f29fbaa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/639]  eta: 0:24:14  lr: 0.000013  loss: 1.8359 (1.8359)  classification: 1.1366 (1.1366)  bbox_regression: 0.6993 (0.6993)  time: 2.2770  data: 1.1841  max mem: 4054\n",
      "Epoch: [0]  [250/639]  eta: 0:05:44  lr: 0.001970  loss: 1.6466 (1.7348)  classification: 1.1115 (1.1213)  bbox_regression: 0.5336 (0.6135)  time: 0.8860  data: 0.0148  max mem: 4355\n",
      "Epoch: [0]  [500/639]  eta: 0:02:03  lr: 0.003927  loss: 1.5896 (1.6548)  classification: 1.0361 (1.0722)  bbox_regression: 0.5564 (0.5826)  time: 0.8861  data: 0.0149  max mem: 4368\n",
      "Epoch: [0]  [638/639]  eta: 0:00:00  lr: 0.005000  loss: 1.4257 (1.6206)  classification: 0.8975 (1.0474)  bbox_regression: 0.5371 (0.5731)  time: 0.8859  data: 0.0158  max mem: 4416\n",
      "Epoch: [0] Total time: 0:09:27 (0.8885 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.008726362038899503\n",
      "0.0005682533818497805\n",
      "Epoch Done\n",
      "Epoch: [1]  [  0/639]  eta: 0:21:07  lr: 0.005000  loss: 1.3550 (1.3550)  classification: 0.8288 (0.8288)  bbox_regression: 0.5262 (0.5262)  time: 1.9835  data: 1.0866  max mem: 4416\n",
      "Epoch: [1]  [250/639]  eta: 0:05:40  lr: 0.005000  loss: 1.3996 (1.4094)  classification: 0.8516 (0.8705)  bbox_regression: 0.5275 (0.5389)  time: 0.8719  data: 0.0156  max mem: 4416\n",
      "Epoch: [1]  [500/639]  eta: 0:02:01  lr: 0.005000  loss: 1.3637 (1.4112)  classification: 0.8481 (0.8733)  bbox_regression: 0.5141 (0.5378)  time: 0.8730  data: 0.0158  max mem: 4416\n",
      "Epoch: [1]  [638/639]  eta: 0:00:00  lr: 0.005000  loss: 1.1340 (1.3901)  classification: 0.6124 (0.8518)  bbox_regression: 0.5315 (0.5382)  time: 0.8713  data: 0.0158  max mem: 4416\n",
      "Epoch: [1] Total time: 0:09:19 (0.8761 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.05471402145851051\n",
      "0.01529191468077514\n",
      "Epoch Done\n",
      "Epoch: [2]  [  0/639]  eta: 0:21:58  lr: 0.005000  loss: 1.0837 (1.0837)  classification: 0.5640 (0.5640)  bbox_regression: 0.5197 (0.5197)  time: 2.0627  data: 1.1745  max mem: 4416\n",
      "Epoch: [2]  [250/639]  eta: 0:05:40  lr: 0.005000  loss: 1.0824 (1.0649)  classification: 0.5689 (0.5480)  bbox_regression: 0.5105 (0.5169)  time: 0.8746  data: 0.0157  max mem: 4416\n",
      "Epoch: [2]  [500/639]  eta: 0:02:01  lr: 0.005000  loss: 0.9282 (1.0119)  classification: 0.4415 (0.5071)  bbox_regression: 0.4902 (0.5049)  time: 0.8735  data: 0.0160  max mem: 4416\n",
      "Epoch: [2]  [638/639]  eta: 0:00:00  lr: 0.005000  loss: 0.9163 (0.9898)  classification: 0.4544 (0.4912)  bbox_regression: 0.4612 (0.4986)  time: 0.8718  data: 0.0156  max mem: 4416\n",
      "Epoch: [2] Total time: 0:09:20 (0.8772 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.20102608911222455\n",
      "0.07925820079586125\n",
      "Epoch Done\n",
      "Epoch: [3]  [  0/639]  eta: 0:16:06  lr: 0.000500  loss: 0.9100 (0.9100)  classification: 0.4386 (0.4386)  bbox_regression: 0.4713 (0.4713)  time: 1.5128  data: 0.6470  max mem: 4416\n",
      "Epoch: [3]  [250/639]  eta: 0:05:40  lr: 0.000500  loss: 0.8163 (0.8461)  classification: 0.3621 (0.3874)  bbox_regression: 0.4524 (0.4587)  time: 0.8734  data: 0.0156  max mem: 4417\n",
      "Epoch: [3]  [500/639]  eta: 0:02:01  lr: 0.000500  loss: 0.8195 (0.8416)  classification: 0.3705 (0.3841)  bbox_regression: 0.4464 (0.4576)  time: 0.8732  data: 0.0160  max mem: 4417\n",
      "Epoch: [3]  [638/639]  eta: 0:00:00  lr: 0.000500  loss: 0.8111 (0.8387)  classification: 0.3517 (0.3816)  bbox_regression: 0.4518 (0.4572)  time: 0.8719  data: 0.0151  max mem: 4417\n",
      "Epoch: [3] Total time: 0:09:20 (0.8766 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.25032762585843676\n",
      "0.10902066335908513\n",
      "Epoch Done\n",
      "Epoch: [4]  [  0/639]  eta: 0:21:57  lr: 0.000500  loss: 0.7250 (0.7250)  classification: 0.3065 (0.3065)  bbox_regression: 0.4185 (0.4185)  time: 2.0624  data: 1.2189  max mem: 4417\n",
      "Epoch: [4]  [250/639]  eta: 0:05:41  lr: 0.000500  loss: 0.7854 (0.8196)  classification: 0.3436 (0.3687)  bbox_regression: 0.4418 (0.4508)  time: 0.8728  data: 0.0158  max mem: 4417\n",
      "Epoch: [4]  [500/639]  eta: 0:02:01  lr: 0.000500  loss: 0.7788 (0.8144)  classification: 0.3369 (0.3663)  bbox_regression: 0.4305 (0.4481)  time: 0.8774  data: 0.0187  max mem: 4417\n",
      "Epoch: [4]  [638/639]  eta: 0:00:00  lr: 0.000500  loss: 0.8294 (0.8147)  classification: 0.3520 (0.3659)  bbox_regression: 0.4646 (0.4488)  time: 0.8730  data: 0.0166  max mem: 4417\n",
      "Epoch: [4] Total time: 0:09:20 (0.8779 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.2512537367135448\n",
      "0.1007149069981072\n",
      "Epoch Done\n",
      "Epoch: [5]  [  0/639]  eta: 0:22:08  lr: 0.000500  loss: 0.8486 (0.8486)  classification: 0.3569 (0.3569)  bbox_regression: 0.4916 (0.4916)  time: 2.0784  data: 1.2355  max mem: 4417\n",
      "Epoch: [5]  [250/639]  eta: 0:05:41  lr: 0.000500  loss: 0.8143 (0.8062)  classification: 0.3654 (0.3577)  bbox_regression: 0.4444 (0.4484)  time: 0.8728  data: 0.0154  max mem: 4417\n",
      "Epoch: [5]  [500/639]  eta: 0:02:01  lr: 0.000500  loss: 0.8048 (0.7979)  classification: 0.3624 (0.3547)  bbox_regression: 0.4368 (0.4431)  time: 0.8748  data: 0.0163  max mem: 4417\n",
      "Epoch: [5]  [638/639]  eta: 0:00:00  lr: 0.000500  loss: 0.7773 (0.7968)  classification: 0.3398 (0.3542)  bbox_regression: 0.4352 (0.4426)  time: 0.8737  data: 0.0150  max mem: 4417\n",
      "Epoch: [5] Total time: 0:09:21 (0.8785 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.27653770480194323\n",
      "0.11301021911707576\n",
      "Epoch Done\n",
      "Epoch: [6]  [  0/639]  eta: 0:17:10  lr: 0.000050  loss: 0.7263 (0.7263)  classification: 0.3361 (0.3361)  bbox_regression: 0.3902 (0.3902)  time: 1.6130  data: 0.7559  max mem: 4417\n",
      "Epoch: [6]  [250/639]  eta: 0:05:40  lr: 0.000050  loss: 0.7957 (0.7719)  classification: 0.3408 (0.3397)  bbox_regression: 0.4295 (0.4323)  time: 0.8728  data: 0.0157  max mem: 4417\n",
      "Epoch: [6]  [500/639]  eta: 0:02:01  lr: 0.000050  loss: 0.7720 (0.7769)  classification: 0.3337 (0.3423)  bbox_regression: 0.4263 (0.4347)  time: 0.8741  data: 0.0159  max mem: 4417\n",
      "Epoch: [6]  [638/639]  eta: 0:00:00  lr: 0.000050  loss: 0.7461 (0.7770)  classification: 0.3302 (0.3420)  bbox_regression: 0.4246 (0.4350)  time: 0.8722  data: 0.0155  max mem: 4417\n",
      "Epoch: [6] Total time: 0:09:20 (0.8777 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.2766780280216814\n",
      "0.11727459789866487\n",
      "Epoch Done\n",
      "Epoch: [7]  [  0/639]  eta: 0:20:31  lr: 0.000050  loss: 0.7546 (0.7546)  classification: 0.3493 (0.3493)  bbox_regression: 0.4053 (0.4053)  time: 1.9275  data: 1.0467  max mem: 4417\n",
      "Epoch: [7]  [250/639]  eta: 0:05:40  lr: 0.000050  loss: 0.7900 (0.7701)  classification: 0.3518 (0.3381)  bbox_regression: 0.4405 (0.4320)  time: 0.8730  data: 0.0156  max mem: 4417\n",
      "Epoch: [7]  [500/639]  eta: 0:02:01  lr: 0.000050  loss: 0.7635 (0.7727)  classification: 0.3344 (0.3397)  bbox_regression: 0.4187 (0.4330)  time: 0.8726  data: 0.0150  max mem: 4421\n",
      "Epoch: [7]  [638/639]  eta: 0:00:00  lr: 0.000050  loss: 0.7827 (0.7733)  classification: 0.3295 (0.3396)  bbox_regression: 0.4414 (0.4337)  time: 0.8741  data: 0.0155  max mem: 4421\n",
      "Epoch: [7] Total time: 0:09:21 (0.8780 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.28475281117671797\n",
      "0.1210359149054303\n",
      "Epoch Done\n",
      "Epoch: [8]  [  0/639]  eta: 0:22:47  lr: 0.000050  loss: 0.7369 (0.7369)  classification: 0.3005 (0.3005)  bbox_regression: 0.4364 (0.4364)  time: 2.1393  data: 1.2633  max mem: 4421\n",
      "Epoch: [8]  [250/639]  eta: 0:05:41  lr: 0.000050  loss: 0.7295 (0.7683)  classification: 0.3147 (0.3381)  bbox_regression: 0.4148 (0.4302)  time: 0.8738  data: 0.0152  max mem: 4421\n",
      "Epoch: [8]  [500/639]  eta: 0:02:01  lr: 0.000050  loss: 0.7666 (0.7727)  classification: 0.3228 (0.3393)  bbox_regression: 0.4338 (0.4334)  time: 0.8745  data: 0.0154  max mem: 4421\n",
      "Epoch: [8]  [638/639]  eta: 0:00:00  lr: 0.000050  loss: 0.7460 (0.7718)  classification: 0.3314 (0.3383)  bbox_regression: 0.4286 (0.4335)  time: 0.8734  data: 0.0154  max mem: 4421\n",
      "Epoch: [8] Total time: 0:09:21 (0.8787 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.2892037788959347\n",
      "0.12570359223282768\n",
      "Epoch Done\n",
      "Epoch: [9]  [  0/639]  eta: 0:18:50  lr: 0.000005  loss: 0.6989 (0.6989)  classification: 0.2991 (0.2991)  bbox_regression: 0.3999 (0.3999)  time: 1.7689  data: 0.8815  max mem: 4421\n",
      "Epoch: [9]  [250/639]  eta: 0:05:40  lr: 0.000005  loss: 0.7764 (0.7713)  classification: 0.3260 (0.3385)  bbox_regression: 0.4368 (0.4328)  time: 0.8738  data: 0.0158  max mem: 4421\n",
      "Epoch: [9]  [500/639]  eta: 0:02:01  lr: 0.000005  loss: 0.7642 (0.7697)  classification: 0.3303 (0.3372)  bbox_regression: 0.4183 (0.4326)  time: 0.8737  data: 0.0154  max mem: 4421\n",
      "Epoch: [9]  [638/639]  eta: 0:00:00  lr: 0.000005  loss: 0.7732 (0.7685)  classification: 0.3399 (0.3366)  bbox_regression: 0.4363 (0.4319)  time: 0.8732  data: 0.0157  max mem: 4430\n",
      "Epoch: [9] Total time: 0:09:21 (0.8780 s / it)\n",
      "Train done, evaluating.\n",
      "Inference done, computing mAp : \n",
      "0.288283601728657\n",
      "0.1257494236614232\n",
      "Epoch Done\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=250)\n",
    "    print (\"Train done, evaluating.\")\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    inference_res = evaluate(model,data_loader_val)\n",
    "    print('Inference done, computing mAp : ')\n",
    "    print(evaluate_res(inference_res, iou_threshold = 0.5, score_threshold = 0.05))    \n",
    "    print(evaluate_res(inference_res, iou_threshold = 0.6, score_threshold = 0.05))\n",
    "    print('Epoch Done')\n",
    "    torch.save(model.state_dict(), 'resnet50_FRCNN_SDD_epoch_%i.pth'%epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a4be94-1b5d-4242-8cf9-c26d6e0b6cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to test evaluation model and show detections\n",
    "\n",
    "# cpu_device = torch.device(\"cpu\")\n",
    "# model.eval()\n",
    "# for images, targets in data_loader:\n",
    "#     g_images = list(img.to(device) for img in images)\n",
    "\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.synchronize()\n",
    "#     outputs = model(g_images)\n",
    "\n",
    "#     outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "#     res = targets, outputs\n",
    "#     break\n",
    "\n",
    "# im = F.to_pil_image(images[0])\n",
    "# targets\n",
    "# # im = to_pil_image(dataset[10][0])\n",
    "# draw = ImageDraw.Draw(im)\n",
    "\n",
    "# for bb in outputs[0]['boxes'][:10]:\n",
    "#     draw.line([(bb[0], bb[1]), (bb[0], bb[3]), (bb[2], bb[3]),\n",
    "#                (bb[2], bb[1]), (bb[0], bb[1])], width=4, fill=(255, 0, 0))\n",
    "\n",
    "# for bb in targets[0]['boxes'][:10]:\n",
    "#     draw.line([(bb[0], bb[1]), (bb[0], bb[3]), (bb[2], bb[3]),\n",
    "#                (bb[2], bb[1]), (bb[0], bb[1])], width=4, fill=(0,255, 0))\n",
    "# im.show()\n",
    "\n",
    "# # # This suggests test set is far from perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4473ad-c591-4d96-ac0c-cfeddbc3fc34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
