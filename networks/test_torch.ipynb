{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf73ca5-02c9-41a5-9a50-2c67a4af0c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.models.detection.retinanet import RetinaNet\n",
    "from torchvision.transforms.functional import  to_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b63ba9b-2b9f-4073-96b6-2cfdad94eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDDDataSET(torch.utils.data.Dataset):\n",
    "    def __init__(self, typeOfDS, transforms=None):\n",
    "        self.typeOfDS = typeOfDS\n",
    "        self.labels = pd.read_csv('/app/host/lacmus/dataset/sdd-lacmus-version/%s_annotations_pedestrian.csv'%typeOfDS, header = None, \n",
    "            names = ['image','x0','y0','x1','y1','class'])\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.image.nunique()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images ad masks\n",
    "        img_name = self.labels.image.unique()[idx]\n",
    "        img_labels = self.labels [self.labels.image == img_name]\n",
    "        img = to_tensor(\n",
    "            Image.open('/app/host/lacmus/dataset/sdd-lacmus-version/'+img_name).convert(\"RGB\")) #convert from tutorial, do we need it?\n",
    "        \n",
    "\n",
    "        # get bounding box coordinates for each mask\n",
    "        num_objs = img_labels.shape[0]\n",
    "        boxes = []\n",
    "        for l in img_labels.iterrows():\n",
    "            boxes.append([l[1]['x0'], l[1]['y0'], l[1]['x1'], l[1]['y1']])\n",
    "\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)         # there is only one class\n",
    "        target[\"labels\"] = labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72369d23-c361-414b-8557-1deec22bdbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = SDDDataSET('test')\n",
    "# im = dataset[10][0]\n",
    "# draw = ImageDraw.Draw(im)\n",
    "\n",
    "# for bb in dataset[10][1]['boxes']:\n",
    "#     draw.line([(bb[0], bb[1]), (bb[0], bb[3]), (bb[2], bb[3]),\n",
    "#                (bb[2], bb[1]), (bb[0], bb[1])], width=4, fill=(255, 0, 0))\n",
    "\n",
    "# # im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f88145-51b2-4d11-9b54-f783178b6c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7290ce25-a74d-4ad2-8a1f-9fca5ae1eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    This function helps when we have different number of object instances\n",
    "    in the batches in the dataset.\n",
    "    \"\"\"\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc868c76-562f-40aa-9d75-441cc9912d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = SDDDataSET('train')\n",
    "dataset_test = SDDDataSET('test')\n",
    "\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=1, shuffle=True, num_workers=4\n",
    "     ,collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=4\n",
    "     ,collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4891861-a61f-4c64-883d-021ccd279dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an instance segmentation model pre-trained on COCO    \n",
    "model = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=False, num_classes=2, pretrained_backbone=True)\n",
    "\n",
    "# the computation device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05c78bc8-d88a-48de-8088-5f2c41474ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "import time\n",
    "import datetime\n",
    "import torch.distributed as dist\n",
    "\n",
    "class SmoothedValue(object):\n",
    "    \"\"\"Track a series of values and provide access to smoothed values over a\n",
    "    window or the global series average.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, window_size=20, fmt=None):\n",
    "        if fmt is None:\n",
    "            fmt = \"{median:.4f} ({global_avg:.4f})\"\n",
    "        self.deque = deque(maxlen=window_size)\n",
    "        self.total = 0.0\n",
    "        self.count = 0\n",
    "        self.fmt = fmt\n",
    "\n",
    "    def update(self, value, n=1):\n",
    "        self.deque.append(value)\n",
    "        self.count += n\n",
    "        self.total += value * n\n",
    "\n",
    "    def synchronize_between_processes(self):\n",
    "        \"\"\"\n",
    "        Warning: does not synchronize the deque!\n",
    "        \"\"\"\n",
    "        if not is_dist_avail_and_initialized():\n",
    "            return\n",
    "        t = torch.tensor([self.count, self.total], dtype=torch.float64, device='cuda')\n",
    "        dist.barrier()\n",
    "        dist.all_reduce(t)\n",
    "        t = t.tolist()\n",
    "        self.count = int(t[0])\n",
    "        self.total = t[1]\n",
    "\n",
    "    @property\n",
    "    def median(self):\n",
    "        d = torch.tensor(list(self.deque))\n",
    "        return d.median().item()\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        d = torch.tensor(list(self.deque), dtype=torch.float32)\n",
    "        return d.mean().item()\n",
    "\n",
    "    @property\n",
    "    def global_avg(self):\n",
    "        return self.total / self.count\n",
    "\n",
    "    @property\n",
    "    def max(self):\n",
    "        return max(self.deque)\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.deque[-1]\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.fmt.format(\n",
    "            median=self.median,\n",
    "            avg=self.avg,\n",
    "            global_avg=self.global_avg,\n",
    "            max=self.max,\n",
    "            value=self.value)\n",
    "\n",
    "class MetricLogger(object):\n",
    "    def __init__(self, delimiter=\"\\t\"):\n",
    "        self.meters = defaultdict(SmoothedValue)\n",
    "        self.delimiter = delimiter\n",
    "\n",
    "    def update(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                v = v.item()\n",
    "            assert isinstance(v, (float, int))\n",
    "            self.meters[k].update(v)\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self.meters:\n",
    "            return self.meters[attr]\n",
    "        if attr in self.__dict__:\n",
    "            return self.__dict__[attr]\n",
    "        raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
    "            type(self).__name__, attr))\n",
    "\n",
    "    def __str__(self):\n",
    "        loss_str = []\n",
    "        for name, meter in self.meters.items():\n",
    "            loss_str.append(\n",
    "                \"{}: {}\".format(name, str(meter))\n",
    "            )\n",
    "        return self.delimiter.join(loss_str)\n",
    "\n",
    "    def synchronize_between_processes(self):\n",
    "        for meter in self.meters.values():\n",
    "            meter.synchronize_between_processes()\n",
    "\n",
    "    def add_meter(self, name, meter):\n",
    "        self.meters[name] = meter\n",
    "\n",
    "    def log_every(self, iterable, print_freq, header=None):\n",
    "        i = 0\n",
    "        if not header:\n",
    "            header = ''\n",
    "        start_time = time.time()\n",
    "        end = time.time()\n",
    "        iter_time = SmoothedValue(fmt='{avg:.4f}')\n",
    "        data_time = SmoothedValue(fmt='{avg:.4f}')\n",
    "        space_fmt = ':' + str(len(str(len(iterable)))) + 'd'\n",
    "        if torch.cuda.is_available():\n",
    "            log_msg = self.delimiter.join([\n",
    "                header,\n",
    "                '[{0' + space_fmt + '}/{1}]',\n",
    "                'eta: {eta}',\n",
    "                '{meters}',\n",
    "                'time: {time}',\n",
    "                'data: {data}',\n",
    "                'max mem: {memory:.0f}'\n",
    "            ])\n",
    "        else:\n",
    "            log_msg = self.delimiter.join([\n",
    "                header,\n",
    "                '[{0' + space_fmt + '}/{1}]',\n",
    "                'eta: {eta}',\n",
    "                '{meters}',\n",
    "                'time: {time}',\n",
    "                'data: {data}'\n",
    "            ])\n",
    "        MB = 1024.0 * 1024.0\n",
    "        for obj in iterable:\n",
    "            data_time.update(time.time() - end)\n",
    "            yield obj\n",
    "            iter_time.update(time.time() - end)\n",
    "            if i % print_freq == 0 or i == len(iterable) - 1:\n",
    "                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n",
    "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
    "                if torch.cuda.is_available():\n",
    "                    print(log_msg.format(\n",
    "                        i, len(iterable), eta=eta_string,\n",
    "                        meters=str(self),\n",
    "                        time=str(iter_time), data=str(data_time),\n",
    "                        memory=torch.cuda.max_memory_allocated() / MB))\n",
    "                else:\n",
    "                    print(log_msg.format(\n",
    "                        i, len(iterable), eta=eta_string,\n",
    "                        meters=str(self),\n",
    "                        time=str(iter_time), data=str(data_time)))\n",
    "            i += 1\n",
    "            end = time.time()\n",
    "        total_time = time.time() - start_time\n",
    "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "        print('{} Total time: {} ({:.4f} s / it)'.format(\n",
    "            header, total_time_str, total_time / len(iterable)))\n",
    "        \n",
    "        \n",
    "\n",
    "def warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor):\n",
    "\n",
    "    def f(x):\n",
    "        if x >= warmup_iters:\n",
    "            return 1\n",
    "        alpha = float(x) / warmup_iters\n",
    "        return warmup_factor * (1 - alpha) + alpha\n",
    "\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, f)\n",
    "\n",
    "def is_dist_avail_and_initialized():\n",
    "    if not dist.is_available():\n",
    "        return False\n",
    "    if not dist.is_initialized():\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_world_size():\n",
    "    if not is_dist_avail_and_initialized():\n",
    "        return 1\n",
    "    return dist.get_world_size()\n",
    "\n",
    "def reduce_dict(input_dict, average=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        input_dict (dict): all the values will be reduced\n",
    "        average (bool): whether to do average or sum\n",
    "    Reduce the values in the dictionary from all processes so that all processes\n",
    "    have the averaged results. Returns a dict with the same fields as\n",
    "    input_dict, after reduction.\n",
    "    \"\"\"\n",
    "    world_size = get_world_size()\n",
    "    if world_size < 2:\n",
    "        return input_dict\n",
    "    with torch.no_grad():\n",
    "        names = []\n",
    "        values = []\n",
    "        # sort the keys so that they are consistent across processes\n",
    "        for k in sorted(input_dict.keys()):\n",
    "            names.append(k)\n",
    "            values.append(input_dict[k])\n",
    "        values = torch.stack(values, dim=0)\n",
    "        dist.all_reduce(values)\n",
    "        if average:\n",
    "            values /= world_size\n",
    "        reduced_dict = {k: v for k, v in zip(names, values)}\n",
    "    return reduced_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e09685db-2177-47d4-a84e-fd2e0e2d8532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n",
    "    model.train()\n",
    "    metric_logger = MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "\n",
    "    lr_scheduler = None\n",
    "    if epoch == 0:\n",
    "        warmup_factor = 1. / 1000\n",
    "        warmup_iters = min(1000, len(data_loader) - 1)\n",
    "\n",
    "        lr_scheduler = warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n",
    "\n",
    "    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # reduce losses over all GPUs for logging purposes\n",
    "        loss_dict_reduced = reduce_dict(loss_dict)\n",
    "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "        loss_value = losses_reduced.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "            print(loss_dict_reduced)\n",
    "            sys.exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
    "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "    return metric_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af8bd293-8950-4ecf-8412-2ae54162ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, data_loader, device='cuda'):\n",
    "    n_threads = torch.get_num_threads()\n",
    "    torch.set_num_threads(1)\n",
    "    cpu_device = torch.device(\"cpu\")\n",
    "    inference_res = []\n",
    "    model.eval()\n",
    "    \n",
    "    for images, targets in data_loader:\n",
    "        images = list(img.to(device) for img in images)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        outputs = model(images)\n",
    "\n",
    "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "        res = targets, outputs\n",
    "        inference_res.append(res)\n",
    "\n",
    "    torch.set_num_threads(n_threads)\n",
    "    return inference_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "747ed96a-b8a2-4337-b7c3-bdae334d154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_ap(recall, precision):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list).\n",
    "        precision: The precision curve (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "    # correct AP calculation\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], recall, [1.]))\n",
    "    mpre = np.concatenate(([0.], precision, [0.]))\n",
    "\n",
    "    # compute the precision envelope\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # to calculate area under PR curve, look for points\n",
    "    # where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97c204f2-fa70-47db-a8e7-3321a023351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyximport\n",
    "pyximport.install()\n",
    "from compute_overlap import compute_overlap\n",
    "\n",
    "\n",
    "def evaluate_res(\n",
    "    inference_res,\n",
    "    iou_threshold=0.5,\n",
    "    score_threshold=0.05,\n",
    "    max_detections=100\n",
    "):\n",
    "    \"\"\" Evaluate a given dataset using a given model.\n",
    "    # Arguments\n",
    "        iou_threshold   : The threshold used to consider when a detection is positive or negative.\n",
    "        score_threshold : The score confidence threshold to use for detections.\n",
    "        max_detections  : The maximum number of detections to use per image.\n",
    "    \"\"\"\n",
    "    # gather all detections and annotations\n",
    "#     all_detections, all_inferences = \\\n",
    "#         _get_detections(generator, model, score_threshold=score_threshold, max_detections=max_detections, save_path=save_path)\n",
    "#     all_annotations    = _get_annotations(generator)\n",
    "#     average_precisions = {}\n",
    "\n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives  = np.zeros((0,))\n",
    "    scores          = np.zeros((0,))\n",
    "    num_annotations = 0.0\n",
    "\n",
    "    for i in range(len(inference_res)):\n",
    "        detections           = inference_res[i][1][0]\n",
    "        annotations          = inference_res[i][0][0]\n",
    "        num_annotations     += inference_res[i][0][0]['labels'].shape[0]\n",
    "        detected_annotations = []\n",
    "\n",
    "        for d in range(detections['labels'].shape[0]):\n",
    "            if detections['scores'][d].numpy() > score_threshold:\n",
    "                scores = np.append(scores, detections['scores'][d].numpy())\n",
    "\n",
    "                if inference_res[i][0][0]['labels'].shape[0] == 0: # no objects was there\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives  = np.append(true_positives, 0)\n",
    "                    continue\n",
    "\n",
    "                overlaps            = compute_overlap (np.expand_dims(detections['boxes'][d].numpy().astype(np.double),axis=0),annotations['boxes'].numpy().astype(np.double))\n",
    "                assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "                max_overlap         = overlaps[0, assigned_annotation][0]\n",
    "\n",
    "                if max_overlap >= iou_threshold and assigned_annotation not in detected_annotations:\n",
    "                    false_positives = np.append(false_positives, 0)\n",
    "                    true_positives  = np.append(true_positives, 1)\n",
    "                    detected_annotations.append(assigned_annotation)\n",
    "                else:\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives  = np.append(true_positives, 0)\n",
    "\n",
    "\n",
    "#     # sort by score\n",
    "    indices         = np.argsort(-scores)\n",
    "    false_positives = false_positives[indices]\n",
    "    true_positives  = true_positives[indices]\n",
    "\n",
    "#     # compute false positives and true positives\n",
    "    false_positives = np.cumsum(false_positives)\n",
    "    true_positives  = np.cumsum(true_positives)\n",
    "\n",
    "#     # compute recall and precision\n",
    "    recall    = true_positives / num_annotations\n",
    "    precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "\n",
    "    # compute average precision\n",
    "    average_precision  = _compute_ap(recall, precision)\n",
    "\n",
    "\n",
    "    return average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deefc4c-87ff-46e6-9bd3-ae7f29fbaa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [   0/2556]  eta: 0:23:38  lr: 0.000002  loss: 1.8204 (1.8204)  classification: 1.1298 (1.1298)  bbox_regression: 0.6906 (0.6906)  time: 0.5550  data: 0.2966  max mem: 1044\n",
      "Epoch: [0]  [ 500/2556]  eta: 0:07:51  lr: 0.000501  loss: 1.6796 (1.7381)  classification: 1.1012 (1.0730)  bbox_regression: 0.5841 (0.6651)  time: 0.2341  data: 0.0066  max mem: 1402\n",
      "Epoch: [0]  [1000/2556]  eta: 0:06:04  lr: 0.001000  loss: 1.2413 (1.6575)  classification: 0.6884 (1.0167)  bbox_regression: 0.5529 (0.6408)  time: 0.2395  data: 0.0065  max mem: 1409\n",
      "Epoch: [0]  [1500/2556]  eta: 0:04:09  lr: 0.001000  loss: 1.6314 (1.5951)  classification: 1.0397 (0.9628)  bbox_regression: 0.5946 (0.6323)  time: 0.2447  data: 0.0062  max mem: 1409\n",
      "Epoch: [0]  [2000/2556]  eta: 0:02:11  lr: 0.001000  loss: 1.5102 (1.5873)  classification: 0.9278 (0.9616)  bbox_regression: 0.5875 (0.6257)  time: 0.2376  data: 0.0066  max mem: 1409\n",
      "Epoch: [0]  [2500/2556]  eta: 0:00:13  lr: 0.001000  loss: 1.4092 (1.5595)  classification: 0.7906 (0.9382)  bbox_regression: 0.5564 (0.6213)  time: 0.2375  data: 0.0068  max mem: 1416\n",
      "Epoch: [0]  [2555/2556]  eta: 0:00:00  lr: 0.001000  loss: 1.3338 (1.5552)  classification: 0.7312 (0.9344)  bbox_regression: 0.5648 (0.6208)  time: 0.2366  data: 0.0073  max mem: 1416\n",
      "Epoch: [0] Total time: 0:10:13 (0.2400 s / it)\n",
      "Evaluation : \n",
      "0.015191224726137334\n",
      "0.002990896999585069\n",
      "Epoch Done\n",
      "Epoch: [1]  [   0/2556]  eta: 0:23:42  lr: 0.001000  loss: 1.3194 (1.3194)  classification: 0.6875 (0.6875)  bbox_regression: 0.6320 (0.6320)  time: 0.5564  data: 0.3027  max mem: 1416\n",
      "Epoch: [1]  [ 500/2556]  eta: 0:07:53  lr: 0.001000  loss: 1.0239 (1.3907)  classification: 0.4929 (0.7846)  bbox_regression: 0.5311 (0.6061)  time: 0.2299  data: 0.0061  max mem: 1416\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=500)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    inference_res = evaluate(model,data_loader_test)\n",
    "    print('Evaluation : ')\n",
    "    print(evaluate_res(inference_res, iou_threshold = 0.5, score_threshold = 0.05))    \n",
    "    print(evaluate_res(inference_res, iou_threshold = 0.6, score_threshold = 0.05))\n",
    "    print('Epoch Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
